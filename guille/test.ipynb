{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../practica_micro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MALDI_binned</th>\n",
       "      <th>Erythromycin</th>\n",
       "      <th>Ciprofloxacin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0002535866911222, 0.0003949856891622, 0.000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0003393276603384, 0.0002025633325117, 9.727...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0001225308701019, 0.0001617988864636, 8.873...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0002821877594324, 0.0006081195988659, 0.000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0003700831426878, 0.0002433899375037, 0.000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        MALDI_binned  Erythromycin  \\\n",
       "0  [0.0002535866911222, 0.0003949856891622, 0.000...           0.0   \n",
       "1  [0.0003393276603384, 0.0002025633325117, 9.727...           0.0   \n",
       "2  [0.0001225308701019, 0.0001617988864636, 8.873...           1.0   \n",
       "3  [0.0002821877594324, 0.0006081195988659, 0.000...           0.0   \n",
       "4  [0.0003700831426878, 0.0002433899375037, 0.000...           0.0   \n",
       "\n",
       "   Ciprofloxacin  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            1.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "[0.0002535866911222, 0.0003949856891622, 0.0004533690825483, 0.0004953216780413, 0.0008012085185987, 0.0008793455192386, 0.0012961220967862, 0.0006312828282373, 4.0394777001594826e-05, 0.000295282659393, 0.0003687859365949, 0.0012783453298406, 0.0017682271395382, 0.0004129705016985, 0.0003170160061868, 0.0001618232416572, 0.0001875933121845, 0.0006287339863895, 0.0001075904408587, 0.000398210335119, 0.0007859624116585, 0.0007895175064824, 0.0048455789477684, 0.0041967482820869, 0.0012349824294868, 0.000906808546419, 0.0007487232514814, 0.0015765870081945, 0.0014077214570617, 0.0007019698226819, 0.0009083381178855, 0.0004739187460689, 0.0004336320460545, 0.0002154731337296, 0.0010873069596135, 0.0036709677641779, 0.0024063463630106, 0.0003269931521057, 0.0003229528879152, 0.0004522419616509, 0.0005489280692616, 0.0011062038590318, 0.000463596941081, 0.0007283674671026, 0.0003652265646089, 0.0005631994440972, 0.0016751924518845, 0.0006053169935411, 0.0004375373537665, 0.0009015556392709, 0.0058605523298508, 0.0049096296403143, 0.0002880890872361, 0.0005584937306562, 0.0016423527163588, 0.0023944326972553, 0.0019035562743374, 0.0009879763343668, 0.0006933025594047, 0.0005718531512262, 0.000574678364074, 0.0007564232263459, 0.0001705388540665, 0.000269247071387, 0.0001800992617494, 0.0002264639070372, 0.0004514027189653, 0.0009020797170145, 0.002162290690871, 0.0016580366715698, 0.0002383841434208, 4.217687860181995e-05, 0.0003335418010353, 0.0016225153604181, 0.0026330339502949, 0.0012237501819013, 0.0003458723129544, 0.0003257834510635, 0.0011343449215457, 0.001447497469744, 0.0023295055883798, 0.006339849181431, 0.0038602121378259, 0.0002440526704061, 0.0002753195686365, 0.0006368742065394, 0.0011047471310563, 0.0009287806909876, 0.0004040181265381, 0.0004457565601669, 6.468440583362267e-05, 0.0004901700998972, 0.0009394333130534, 0.0025225004414814, 0.0025425735720854, 0.001146585144507, 0.0006075999801988, 0.000403283829345, 0.0014128651144389, 0.0014832769253316, 0.0007682455437061, 0.0009356765978389, 0.0006516764572091, 0.0004794715153148, 0.000191652813208, 7.815867567776558e-05, 0.0006835142738942, 0.0008540475398267, 0.000864136275428, 0.0006678599769558, 0.0004784682837054, 0.0005607680300771, 0.000365057114503, 0.0001279395696563, 0.0008893870775716, 0.0008869355678966, 0.000322649168751, 8.425854580076329e-05, 0.0003132405092779, 0.00067443741048, 0.0007610131560988, 0.0008845364671334, 0.0007786206119377, 0.0002089276397484, 0.0001967523286358, 6.618207962102123e-05, 0.0005188868653975, 0.0012821908052085, 0.0007455575517484, 0.000707769311593, 0.0004874602179387, 0.0003813410518745, 0.0003134412411542, 0.0005482555210395, 0.0004335918735355, 0.0011466336457641, 0.002942872855395, 0.0012712035669856, 0.0001902923978218, 0.0003606577201183, 0.0004697779120806, 0.0003758772793861, 0.0003678917290558, 0.0004511778774832, 0.0002999584942778, 0.0001051221068728, 0.0001009744760149, 3.8558346569215294e-05, 0.0005127022802745, 0.0008380001307684, 0.0005124670143238, 0.0001320999712449, 0.0002656685916979, 0.000482662629122, 0.0003289570424502, 0.0002854263595194, 0.0004722625754899, 0.0005392508247795, 0.0001390361656466, 6.148713061875557e-05, 0.0001834361811626, 0.0002124991772672, 0.0002676349259186, 0.0002371482971773, 0.0003756245378128, 0.0003389418748453, 0.0001261379624105, 3.7650032812086985e-05, 0.0005465013389628, 0.0004021095344797, 9.938332364366765e-05, 0.0009292305965441, 0.0011134815593489, 0.0009649238159843, 0.000968737591491, 0.0003545021306163, 0.0001682325218744, 0.0003689071171095, 0.0004311851425014, 0.000484250718585, 0.000155529364305, 0.0001014106314579, 0.0007331962747209, 0.0015694814831019, 0.0010182827370246, 0.0001043792723551, 0.0001644598825038, 3.435136625097177e-05, 0.0001417092355927, 0.000160346151332, 0.0005045854886516, 0.0006370048039294, 0.0003389395339744, 0.0004411452053451, 0.0005569968545992, 0.0003729814567052, 0.0003986486387582, 0.0005499623863179, 0.0005033807834575, 0.0001751822063658, 2.845018435667574e-05, 0.0001723025693312, 0.0001961682242136, 0.0002880141531582, 0.000343621123826, 0.0001723525343978, 5.8847160082849e-05, 0.0002637521397075, 0.0002842098350857, 5.086116543358717e-05, 0.0005842657393088, 0.0010511620794342, 0.0006686161655713, 6.852348536578377e-05, 0.0001634178210622, 0.0006389501616064, 0.0046915934331278, 0.0060278346814179, 0.0026753272643285, 0.0004432165786939, 0.0007698568603055, 0.0004169931641899, 0.000113648929981, 0.0005952507792745, 0.001009454109595, 0.0005070277941644, 2.5504021725588456e-05, 0.0002247425620454, 0.0002894842114173, 0.0006161393440479, 0.0006807182992368, 0.0003211212033157, 0.0002434362517775, 0.0001320741762708, 0.000143328375827, 0.0004680910014886, 0.000662050847643, 0.0005240191971861, 0.0003535199346116, 0.0003981639338103, 0.0001970248659861, 0.000267344328437, 0.000215309352385, 4.743268445057053e-05, 0.0003530715071953, 0.0002060822893307, 3.358231998543312e-05, 0.0001646462808227, 0.0002061428432976, 0.0001202251790467, 0.0002410001204183, 0.0003194792748381, 0.000258016108059, 0.0021587003981547, 0.003763228788378, 0.0020110514310953, 0.0005395577049573, 0.000588863175444, 0.0005040220517558, 0.0004018425336721, 0.000858702171716, 0.0009742807679456, 0.0005237742389501, 0.0002512658282064, 3.660903312964258e-05, 0.0001521902190381, 0.0003787837593064, 0.0005683149584338, 0.0013114278549063, 0.0015454184845919, 0.0005538607739961, 5.186828919731468e-05, 0.0003814731338014, 0.0004138958255394, 0.000502426502757, 0.0008671254527781, 0.0005032105542461, 5.592553003836391e-05, 0.0002069334532289, 0.0005872959667329, 0.0004376812698532, 0.000304084678565, 0.0004611291264362, 0.0002481116724061, 7.792962344896943e-05, 0.000224124035518, 0.0003578141669213, 0.0004801635598447, 0.0005011653858882, 0.0007645295842614, 0.0007758759284284, 0.0002384423571118, 0.0002270214408066, 0.0001213768635157, 0.0001169141687152, 0.0003878209298928, 0.000446071720282, 0.0006848708769927, 0.0004027032844493, 6.442920742916875e-05, 0.0002836113630118, 0.0002587421489822, 0.0002235364514935, 0.0002594223198613, 0.0001831370337455, 0.0001211815169966, 0.0004994816164882, 0.0007671602239233, 0.0002469045462212, 9.424140203897798e-05, 0.0003435545719592, 0.0010308103121582, 0.002723488898652, 0.0021970056218766, 0.0003850067092562, 4.803446739925272e-05, 0.0002847694229224, 0.0002327886936825, 0.0002904875068851, 0.00049814118075, 0.0002920712936264, 0.00107068658437, 0.0022832687211574, 0.0014684235029706, 0.0002067703057021, 0.0004214069167966, 0.0007498401259764, 0.0007862433833097, 0.0004215539582999, 0.0001104599932735, 5.53171779262112e-05, 0.0002334918843019, 0.0002665784918892, 0.0001582321875362, 0.0004051982371274, 0.0028148360158291, 0.0039492761336438, 0.0014490901721023, 0.0004098720261204, 0.0004628250280605, 4.057188528422295e-05, 0.0001919406880206, 0.0004615384124025, 0.0005781817393089, 0.0003870327697418, 9.57978863218768e-05, 0.0001541540417062, 0.0005684092681324, 0.0019372783199345, 0.0018902169587198, 0.0004015069201529, 0.0017818849658777, 0.0034848975021172, 0.002150151757555, 0.0005263688473325, 0.0003197733082484, 0.0006408931371632, 0.0003365701807257, 0.0001192971334954, 0.0002615673953284, 0.0005070970823086, 0.0007682212505484, 0.0004856189004841, 5.381925518972223e-05, 0.0002866015410128, 0.0004857827124755, 0.000233218354242, 0.0001177187015648, 7.03387948711508e-05, 0.0001075537990847, 7.01477484367411e-05, 0.0001316518255784, 1.0392790507838282e-05, 0.000146101051004, 0.0002327570868715, 0.0002124489399034, 9.39571871613824e-05, 0.0002531939446592, 0.0002507821745536, 0.0001900683353247, 0.0005664322484387, 0.0007696224584642, 0.00020379035869, 4.018299755012551e-05, 0.0002196010954573, 0.0002660692251299, 0.0002255277015113, 0.0003124025117255, 0.0003649081268389, 0.0001856859007886, 0.0001107512220076, 0.0012217650413775, 0.0048675042488646, 0.0044064241935961, 0.0018431167618557, 7.316690954140375e-05, 0.0001142073690092, 0.0006665909459314, 0.0011455952841044, 0.0008941417427204, 0.0004000886828463, 0.0002751790866132, 0.0009246387259277, 0.0028244470566026, 0.0039565171414386, 0.0021563030669193, 0.0006687794883878, 0.0003264165959012, 0.0002704870013705, 0.0001093688970782, 0.0003495918342187, 0.0005815192822829, 0.0004495342686944, 0.0002247411745372, 0.0003082417298735, 0.0002135169089626, 0.0002985571105292, 0.0004895919250533, 0.0001677179216024, 1.1491969231994446e-05, 0.0001554141349144, 0.0002247896583522, 0.0002502700371519, 0.0003312224932091, 0.0004518146812983, 0.0016651049378435, 0.001730107644758, 0.0010400251652604, 0.0002596127429494, 0.0004132804175337, 0.0010146479069428, 0.0008483208587153, 0.0005812089116925, 0.000200387018678, 6.079027683281099e-05, 0.0007415522835823, 0.0009702822726049, 0.0005429815209972, 3.01051326049086e-05, 0.0002277003317851, 0.0002384251637905, 0.00010122685251, 0.0002775491887163, 0.0002593285382533, 5.6369228596206914e-05, 5.543553211011281e-05, 0.0003484267121158, 0.0003073261812927, 0.0003151961604544, 0.0001304637200527, 0.0001232872073992, 0.0001204547055872, 0.0001112649156912, 0.0001194637274141, 0.0001427919746382, 0.0002642284422999, 0.0003126305625879, 0.0003769503380967, 0.0001576621267507, 4.943201194638871e-05, 0.0002727378810076, 0.0005058461974256, 0.0001843084037802, 7.953343034649666e-06, 8.607722661322647e-05, 0.0001773121880444, 4.974882269153043e-05, 7.246189195565408e-05, 0.0001864652274011, 0.0005715235124668, 0.0007940491805269, 0.0007347105473524, 0.0002992385636366, 0.0027487169345604, 0.0052530563108503, 0.0055190731988188, 0.0014814502177456, 0.0004055726540854, 0.0006052381161137, 0.0007912517361855, 0.0021705469516758, 0.0055172551368967, 0.0079067315458792, 0.0031472791854673, 0.0010576553003858, 0.0009824648876245, 0.001040233876579, 0.0011149934148514, 0.0015379649239644, 0.0007286126572405, 9.806398666803848e-05, 7.370306765355375e-05, 0.0001042658059432, 0.0002406976014056, 0.0001135042610735, 4.1605553669436544e-05, 5.144771818775453e-05, 0.0002655923104604, 0.0009397520637173, 0.0007997494663221, 0.0004815227098053, 0.0003869907804557, 0.0005265962704344, 0.0009305645934622, 0.0006530539839979, 0.0001483250266911, 0.0001326558975798, 0.0003555627148035, 0.0003764508073445, 4.839988244245469e-05, 8.287153793344029e-05, 0.0002847518246049, 0.0004844782545694, 0.0005870890551348, 0.0001739090009867, 6.615174613045405e-05, 0.0002740439654426, 0.0002951433143252, 0.0002368402249316, 0.0001723157837902, 0.0001801733512384, 0.0002336231752093, 9.1501106710617e-05, 0.000193881696405, 0.0003085861657025, 0.0002231926444178, 3.35252771435036e-05, 0.0004214201245554, 0.0015534956968034, 0.0022165583907964, 0.0007020171897903, 8.463443573428922e-05, 0.0002013929750246, 0.0002427962440604, 0.0004695719573628, 0.0006809072111516, 0.0004500197146846, 0.0002054946922378, 6.143505545886261e-05, 9.515821281796052e-05, 0.0003153022517101, 0.0004722295784579, 0.0002141784254844, 2.3363049956813053e-05, 2.982800619007459e-05, 2.423162343373324e-05, 0.0001472890674266, 0.0003593905773673, 0.0001938309534153, 0.000232808921215, 0.0003186971385984, 0.0001600143223, 7.48022653088319e-05, 1.9866396802817176e-05, 0.0001794888567966, 0.0002517657254332, 0.0001808408647319, 0.0001604070267643, 0.0001292004991953, 2.420888850777635e-05, 4.1100361211437046e-05, 0.0003044137616542, 0.0004990544920109, 0.0005033852537797, 0.0008457279509178, 0.0008129581604949, 0.0006103011185455, 0.0002260910523795, 7.63016200947044e-05, 0.00019041974398, 0.0003367190662948, 0.0004368109355368, 0.0005848007518391, 0.0005170852897513, 0.0004899994236212, 0.000248554057758, 0.0001127471330956, 7.77816132497928e-05, 0.0003508041601084, 0.0004153577088913, 0.0003828927999876, 0.0003311903063443, 0.0004812114390625, 0.0006223773489633, 0.000410709821347, 2.9001358664303e-05, 0.0002549503044034, 0.0006383614277825, 0.0006926401052447, 0.0006971566244514, 0.0003754141366892, 0.0005275903302639, 0.0005842133989425, 0.0004886419328937, 0.0025291596634469, 0.0038493804654193, 0.0026838604810307, 0.0008680868974738, 0.0007338020044528, 0.0004710169577541, 0.0002391315126845, 0.0003731602501501, 0.0004978438078265, 0.0002483278180533, 5.789036844321769e-05, 0.00014888388201, 0.0001880163811973, 0.0002115286091285, 0.0003606351602203, 0.0003360687244355, 6.027457189519416e-05, 1.3270117275799244e-05, 9.31351111603372e-05, 0.0001654003398355, 0.0001133052748797, 0.0003185402100207, 0.0004312116765361, 0.0003906998376828, 0.0002501850558376, 0.0003187453967937, 0.0003344810634408, 0.000193271397817, 0.0001110620128678, 6.130388359186079e-05, 7.004249949751584e-05, 1.2180021671196496e-05, 9.89221677736406e-05, 0.0002301548460005, 0.0003287706724672, 0.0001085255791157, 5.798657211291656e-05, 0.0002544103202674, 0.0002091214130372, 0.0001274971903671, 0.0001182298159845, 9.092871720079228e-05, 5.886967504456951e-05, 4.249908965158263e-05, 5.0258355445136e-05, 4.790908065029008e-05, 7.679894201851798e-05, 9.030070428885851e-05, 5.971714253439874e-05, 1.3228763256630946e-05, 0.0001708764868037, 0.0002490149519074, 0.0001405495177634, 5.925111573922268e-05, 9.293395594798073e-05, 0.0003357671573365, 0.0003459638912039, 9.941490871691876e-05, 1.35651426899748e-05, 7.824629913816195e-05, 0.0002183378662361, 0.0001704400409961, 9.703458177815268e-05, 7.685218981696514e-05, 0.0001813829131264, 0.0003197837174567, 0.0004622170391614, 0.0004415221658975, 0.000307229380585, 0.0002338858657496, 0.0001846562429089, 0.000233712994634, 0.0001718409633645, 8.96031547596884e-05, 0.0001097163345772, 3.823575372303504e-05, 3.062255773781568e-05, 5.100551653387144e-06, 9.11700218967799e-05, 0.000124623524214, 0.0001635990279438, 0.0001265251962882, 0.0001642004867283, 0.0003034206926583, 0.0004120622771003, 0.0002113145913547, 0.0001067459751011, 0.00041930766704, 0.0013427074796282, 0.0015255140173454, 0.0008028649386026, 0.0003129777531072, 0.0004333490624255, 0.0004901438183643, 0.0004915758463976, 0.0003029154237093, 4.331381208095844e-05, 0.0001017860076206, 0.0005976010396951, 0.0006279736719349, 0.0003484768112943, 0.0001102692274776, 0.0001124754167165, 0.0002503862538524, 0.0003021864990625, 0.0002945872479941, 0.0001699212788615, 6.909690451717818e-05, 2.552811745200742e-05, 7.77546353225496e-05, 0.0002460448311466, 0.0002250735368469, 0.000251410280438, 0.000307824803756, 0.0003557455054134, 0.0001604667763883, 5.21426902664316e-05, 2.287744886907489e-05, 0.0001511344318781, 0.0001894333169691, 0.0001120093687003, 3.99657742741436e-05, 0.0001278395415303, 0.0001293991343473, 0.000167260808801, 0.0002858251103783, 0.0002079840022914, 4.6671142110746166e-05, 7.74649326179202e-05, 0.0002203244040733, 0.0003263478223349, 0.0005199002891629, 0.0006882056239073, 0.0005337775014641, 0.0001723296877451, 4.2119399393875226e-05, 0.000273607743216, 0.0004327252614549, 0.0003995139626019, 0.0002313366176699, 0.0002860292275122, 0.0004330651686398, 0.0003832917205254, 0.0005069421651323, 0.0004480851341707, 0.0001396672469792, 4.620046115047469e-05, 0.0001659830005084, 0.0001412287993263, 2.998005245704395e-05, 0.0001180386066545, 0.0001377439827639, 7.248224143728289e-05, 7.707955437460999e-05, 6.280141122218794e-05, 4.5069849147802e-05, 0.00014929901895, 4.661732356128771e-05, 1.4849960073639248e-05, 3.573987698370834e-05, 0.0002333347003318, 0.0003279624454329, 0.000386704573563, 0.0002800851868612, 0.0003629142878291, 0.0003726555437807, 0.0001989529945384, 2.901035700214119e-05, 6.37841327232686e-05, 0.0004567563319716, 0.0007689600621318, 0.0009945812619528, 0.0008205011632184, 0.0015756737513287, 0.0078074172404472, 0.0120120333798149, 0.0156976407769727, 0.0085874910685433, 0.0024206776229404, 0.0008561352817826, 0.0011419514384098, 0.0012275385707933, 0.0010574343721346, 0.0006714058949316, 0.0004521406060402, 7.055226599288959e-05, 0.0004205770210489, 0.0022785314961447, 0.0037678426194534, 0.0028662973314126, 0.000783587338647, 0.0002021531018215, 0.0003027061977522, 0.0003388830311906, 0.0003512532030005, 0.0006406978757634, 0.000832483017249, 0.0008507319112781, 0.0002163156736221, 0.000192027605154, 0.001150512681396, 0.0016571391849029, 0.0010772695694663, 0.0003470856527191, 0.0002780674904676, 0.0002200701177466, 3.7671883973501113e-05, 0.0001767893473839, 0.000374568098819, 0.0005228248659659, 0.0002022627128449, 2.850602065626582e-05, 0.0003165393317303, 0.000679405368451, 0.000470139185336, 0.0002709022712439, 7.093385200765923e-05, 8.463477060060916e-05, 0.0003783496351131, 0.0004394728225072, 0.0007896089227923, 0.001922505873633, 0.0030305432537506, 0.0024363702527101, 0.0010037152503435, 0.0009166872171477, 0.0009896818232105, 0.0008963198888536, 0.0006593297147246, 0.0003422913903478, 0.0001513074946805, 0.0001206995479846, 0.0004525099545132, 0.000528294890223, 0.0002488486596578, 0.0001529947092738, 0.0002226573803933, 0.0001426334426559, 8.98083490807186e-05, 0.0001407426023429, 0.0001865387825588, 0.0001440244917482, 1.980834406527025e-05, 9.91542708264523e-05, 0.0002233839933278, 0.0003264088390864, 0.0003009790448527, 0.000303310308094, 0.0002195022047938, 0.0002952295656651, 0.0003727648846768, 0.0002304288191596, 0.000190646968327, 0.0002127158178913, 0.0001171130199254, 2.203857606986736e-05, 0.0001137302631129, 0.0001767801698232, 0.0001804816649296, 6.902569755605775e-05, 2.626463226787097e-05, 8.301361343495399e-06, 6.962578043721282e-05, 9.4717237520263e-05, 0.0002214460966466, 0.0002645245934923, 0.0003886473197895, 0.0004361558543404, 0.0007313257859127, 0.0018262753739959, 0.002326975039883, 0.0025872575900194, 0.0010033397791941, 0.0004317179425598, 0.0004035313238885, 0.0005885654689429, 0.0006640302660807, 0.0004208946637081, 0.0001943431026743, 4.5229621026631104e-05, 0.0001697080032456, 0.0001711735580828, 0.0003662863118788, 0.0004354380040495, 0.0001952285740401, 7.481917781267355e-05, 0.0010475024646329, 0.00211782019438, 0.0016337849846301, 0.0009950175039358, 0.0002995604199923, 4.232933136316796e-05, 4.292379715139552e-05, 0.0001350921894747, 0.0001909459243651, 0.0001752581255911, 8.75544225249218e-05, 7.617769945233961e-05, 0.0002759389351222, 0.0004758391797915, 0.0004757648446605, 0.0001887288175551, 0.0001559736143109, 1.81626264791239e-05, 1.367525995801233e-05, 7.071359041791936e-05, 0.0002743920407249, 0.0003039044379839, 0.000439261761314, 0.0002567110089532, 0.0001615106029182, 0.0003680650364177, 0.0005537312970628, 0.0004139349681683, 0.0004124968943611, 0.0002623405076814, 0.0001409943712107, 0.000121987021383, 5.8883099539947694e-05, 0.0002190846640503, 0.0003323091916385, 0.0002771131850013, 0.0002089350192512, 6.887731023089503e-05, 1.3623065118609349e-05, 0.0001666471446435, 0.0003616992828801, 0.0003301757213063, 0.0003136438302781, 0.0001792405674528, 7.92320057541362e-06, 0.0001214107635866, 0.0002120221572718, 0.000311256792033, 0.000111648781201, 1.717717711800722e-05, 7.479145066918106e-05, 0.0001697124055656, 0.0001454696897142, 0.0001255465187209, 0.0001510014989145, 0.000529635659935, 0.000875138601259, 0.0015379164189526, 0.00457482481199, 0.0056109000671026, 0.0028313236865465, 0.00102828533662, 0.0007079192548957, 0.001280392333982, 0.0015940245294327, 0.0011254547758088, 0.0008386056837376, 0.0001755160159902, 0.0002685706967176, 0.0007468970866503, 0.0007316839943326, 0.00072636954263, 0.0003063884254255, 0.0003002395740019, 0.0005941723873501, 0.0005541706385165, 0.0003665576707598, 1.7343745971602218e-05, 0.0001611983616625, 0.0004021768830148, 0.0002798123178003, 0.0002404097525046, 0.0001472563301328, 0.000132558910535, 2.2634672445322377e-05, 0.0001127096994484, 0.0001274923096348, 4.972467117608296e-05, 4.023571920494791e-05, 3.099994378934943e-05, 3.486303220707813e-05, 0.0001547287028731, 0.0002210834667377, 0.0001728989231041, 7.19350924581496e-05, 0.0001685106767546, 0.0001719531397506, 0.000354325395546, 0.0002910923635607, 0.000826632797324, 0.0012917495419457, 0.001645584476201, 0.0007663293786409, 0.0001508404613454, 0.0002872087892031, 0.0003206510898821, 0.0005606480048249, 0.0005033832656715, 0.0004630566314454, 8.928629772236836e-05, 4.8115912890831134e-05, 0.0002163804071888, 0.0004596918678989, 0.0003161282644688, 0.0001600712733347, 0.0001467101831486, 9.809721760346e-05, 5.5521764300720815e-05, 2.2833965811061e-05, 1.688879285544964e-05, 9.570591140913063e-06, 5.868639878239188e-05, 5.134240792057056e-05, 8.780724609471429e-05, 7.23623405328267e-05, 0.0002742883956674, 0.0004159940955829, 0.0004674831589344, 0.0003455635401831, 0.0006278633471243, 0.0015601593793938, 0.0043091571047817, 0.0053003857302417, 0.0026421768337264, 0.0008733217267264, 8.56081798676312e-05, 0.0002285144474849, 0.0006094557929368, 0.0014275439494326, 0.0010763462428873, 0.0005879265463281, 3.006796430830975e-05, 0.0001261812804945, 0.0006677665192826, 0.001943825028557, 0.0017210883097924, 0.0011279262975804, 0.0002124350747797, 0.0002109032700797, 0.0003158537970938, 0.0005027850725679, 0.0004531715383679, 0.0003872811878406, 0.0002493780974458, 0.0001202887925749, 0.0002014647482575, 0.0003505262233429, 0.0006164588383087, 0.000357413188637, 0.0001417042753266, 7.82766898969631e-06, 0.0001476805226124, 0.0001974615355476, 0.0002529321072128, 0.0001125373282041, 9.05868798175126e-05, 4.242791802567378e-05, 6.276734818154406e-06, 6.202492601930006e-05, 0.0002538182272775, 0.0002391948662601, 0.0002082972440237, 0.0001716417154172, 0.0001082354728866, 0.0002581407177463, 0.0002918978557246, 0.0003796259671626, 0.0001491889819441, 9.323059428939723e-05, 1.899861461028811e-05, 0.0001452999159542, 0.0001362274821199, 0.0001625428368437, 0.0002177714325049, 0.0001623100917754, 5.547931371622604e-05, 1.8074468451430868e-05, 0.0003181231715853, 0.0005872789915848, 0.0006964325568823, 0.0006556599715724, 0.0002675122896618, 0.0001275591215111, 4.519579432533264e-05, 0.0001367591820624, 0.0002038685479158, 0.0002258892524991, 0.0001445793055245, 0.0001627876354382, 0.000455314490073, 0.0009955577929232, 0.0020507988047556, 0.0015213076697572, 0.0008043292518945, 0.0002247797168793, 4.197963309010855e-05, 0.000234608958295, 0.0004336894460933, 0.0007372575656237, 0.0003685221919799, 0.0001204019021776, 2.28331130526785e-05, 7.14766631829027e-05, 3.700796784070516e-05, 6.465770880828439e-05, 0.0001344430974601, 0.0004334191978091, 0.0004312677056351, 0.0005588983878683, 0.0003726531342892, 0.0012117239306839, 0.0047998502264509, 0.0060491204980174, 0.006429111653285, 0.0023030136215592, 0.0006148032362015, 0.0003438359844181, 0.0004411496120652, 0.0007694724170492, 0.0004912597065118, 0.0002711027097803, 9.029949133896212e-05, 3.332475158487367e-05, 0.0002149204666367, 0.000975978139702, 0.0009887908014517, 0.0007272535295913, 0.0001288387322507, 4.561604373080436e-05, 0.0001002589545837, 9.96168424464071e-05, 0.0002237022285885, 0.0003533295543917, 0.0002230465596131, 8.81037840014115e-05, 0.0001427748189995, 0.0003718766325214, 0.0007004174153237, 0.0005296860441814, 0.0004391599369917, 0.0002649813926685, 2.321332976222731e-05, 2.894482587299614e-05, 0.0001707612178679, 0.0001627457769701, 0.0001634676505556, 9.49919716642362e-05, 2.04177720306925e-05, 1.771162360200835e-05, 0.0001382305453724, 0.0002674850257416, 0.0003195843008509, 0.0002334996450409, 0.0001738232756063, 9.474967760123848e-05, 0.000164826635386, 0.0004987790952495, 0.0009419931819318, 0.0006125378728661, 0.0003593873128956, 0.0002142900293448, 0.0001166642890499, 2.846016952704488e-05, 3.7448873762979e-05, 1.773454173429853e-05, 6.796448184117856e-05, 8.809963703630722e-05, 1.325095299902172e-05, 9.822511264925109e-06, 2.423172306632311e-05, 1.617821664477182e-05, 2.364694420598942e-05, 0.0001212280488673, 0.0001342122294179, 9.818928903338217e-05, 5.832281187112827e-05, 0.0001254599945775, 0.0001423972180984, 0.000305288488013, 0.0005146411273648, 0.000903225266155, 0.0011177784301962, 0.0012257766778086, 0.0008821430815006, 0.0020345596148573, 0.0070513896609042, 0.0083459979417376, 0.0071783120772092, 0.0039594010992664, 0.0004723771292761, 0.0001309935535433, 0.0004491665167634, 0.0006672858811214, 0.0007825429982979, 0.0005625131217609, 0.0002040562753654, 9.002875639321873e-05, 0.0008501481612848, 0.0028540516786798, 0.002883640011123, 0.0022343120935726, 0.0009844635104788, 0.0002336490514654, 6.61102670037712e-05, 0.0002097870632571, 0.0005968240074081, 0.0006174808722547, 0.0004890470269983, 0.0002243691657263, 0.0001793100299019, 0.0004304543634052, 0.0007613102918092, 0.0009427639575032, 0.0004196438535452, 0.0001428807896128, 2.970442564987845e-05, 6.959716363396485e-06, 1.9196644688370387e-05, 0.0002147870886749, 0.0003831994165914, 0.0004128124423838, 9.61573337739811e-05, 0.000123545727208, 0.0003675637938736, 0.0006757151143149, 0.0003760879039374, 8.164336061349994e-05, 3.1377429960528845e-05, 0.0002181639900033, 0.0004309957689514, 0.0005565479962858, 0.0006992655769128, 0.0004075377668371, 0.0001612414070052, 1.695469654490707e-05, 0.0001760195722641, 0.0003029010044834, 0.0003037062917131, 0.0002574589072127, 0.0001488896469197, 3.059710066975449e-05, 9.76495079501613e-06, 0.0001320973093092, 0.0003398500000073, 0.000502571242495, 0.0003204198902023, 0.0001153318951205, 7.50568766941445e-05, 0.0001201387951971, 9.84748572805224e-05, 0.0001609745574017, 0.000235296866527, 0.0002996301176601, 0.0001124649499593, 7.852403454164444e-06, 6.193562981181543e-05, 0.0001449222530223, 0.0001404808479381, 4.109334795358375e-05, 6.1230257967934e-05, 8.0425016782774e-05, 1.3058833931321038e-05, 3.9171007519355765e-05, 0.0001897761307308, 0.0002898707852838, 0.0003125244065871, 0.000827436182618, 0.0011968432165954, 0.0012538572993816, 0.0008210280137154, 0.0004385839235741, 0.0002785129954788, 0.0002847014269543, 0.0003641764112378, 0.0003973088977334, 0.0002455725716385, 1.3468449699552595e-05, 4.741572460905423e-05, 0.0001306546689477, 0.0001572819176769, 0.000261037246215, 0.0002006743556949, 0.0001069849529916, 2.2029894766934057e-05, 6.03809339971547e-06, 4.1868431541440914e-05, 0.0001666954291954, 0.000176422214055, 0.0001421724160978, 0.0001525865619112, 0.0003782600141907, 0.0004869969291027, 0.0005090003870921, 0.0003963019185983, 0.0002224173405669, 0.0001392874130339, 0.0003240808037315, 0.000380789599354, 0.000361672161984, 0.0002533739057487, 0.0004521361328778, 0.0020328730660086, 0.002857997057283, 0.0027808102559419, 0.0016534735046703, 0.0005394889518743, 0.000126508883722, 0.0001609121302006, 0.0002471400271929, 0.000236812630162, 0.0001302700316565, 2.363148320245325e-05, 1.5647316954109285e-05, 9.21359549402592e-05, 0.0002215969068592, 0.0003581643143942, 0.0004847976357438, 0.0005763011611908, 0.0005292329336696, 0.0004089080291082, 0.0008627518813564, 0.0016867022753966, 0.00227022851029, 0.0019311570821741, 0.0009943940770609, 0.0002567107468118, 4.208261468314568e-05, 0.0001930677596702, 0.0004764646517337, 0.0005510524256273, 0.0003591073564119, 0.0001224098971989, 1.387787382186733e-05, 0.0002229319807327, 0.0003821102378604, 0.0004430851188109, 0.0002956603506495, 5.3385332022028406e-05, 2.07649185743375e-06, 1.6425286347851622e-05, 0.0001398307460928, 8.01031823185855e-05, 5.120979524226537e-05, 1.5113293289488826e-05, 3.729805159141992e-06, 2.015357807996604e-05, 0.0001045470458182, 0.0002784046649515, 0.0004900606503082, 0.0004004231399431, 0.0003130693342751, 0.0002198683672389, 8.72458930319688e-05, 3.4158016570773224e-05, 8.46889193557864e-05, 0.0001317651822356, 0.0002109246216891, 0.0001185509114502, 8.47466753122643e-05, 0.000109923059038, 0.000191122973443, 0.0001352194429347, 2.797515000219321e-05, 1.357725707950077e-05, 0.0001710167869241, 0.0003610959556278, 0.0002981387817667, 0.0002516650293426, 0.0002057636339484, 0.0002130185521083, 0.0002038455209959, 0.0002488283526196, 0.0002313313000277, 0.0002428093437037, 0.0003038796185253, 0.0002744344777721, 0.0001858851248742, 5.336420914300708e-05, 8.008644689860861e-06, 7.165383402105561e-05, 0.0001556912154574, 0.0001515143040915, 7.28313142477287e-05, 1.4519240156572273e-05, 6.696221834585276e-05, 0.0001508043594057, 0.0001664597191488, 7.96699129203512e-05, 5.058350093387964e-05, 1.271397998437539e-05, 1.5544549773811635e-05, 9.557648785634222e-06, 8.376399572183733e-05, 0.0001496221919398, 0.0002345828741511, 0.0002297324811097, 0.0001730359440961, 0.0001874711914174, 0.0001722721735961, 0.0001689950129593, 9.43682139391614e-05, 7.236644734431e-05, 6.318216820202641e-05, 2.932056123255989e-05, 1.0741726790357936e-05, 8.671998945960875e-05, 0.0002251539921797, 0.0002394611208071, 0.0002025338088493, 0.0001082628524834, 7.890768400062922e-05, 5.068543403757625e-05, 1.444466059903654e-05, 5.295433581755862e-05, 0.0001453395603727, 0.0001998106392086, 0.0001142464439741, 6.899713068680308e-05, 9.98655784701723e-05, 0.0001659422024366, 0.0001773090272559, 0.0001201101588116, 0.0001088750576173, 7.86170575869997e-05, 8.583367818770909e-05, 2.6881479866027623e-05, 1.6721643689095303e-05, 2.614092153250002e-05, 0.0001000099245277, 0.0001910635915753, 0.0001943731272877, 6.910790581592512e-05, 1.407569408771602e-05, 3.6327015382815606e-05, 5.53539659881776e-06, 2.836182819126883e-05, 8.89080601641358e-05, 0.0001600610405437, 0.0001887631819108, 4.198852133498283e-05, 6.387544009522526e-05, 0.0002594314804047, 0.0003858556168633, 0.0002661483987192, 4.614836647025514e-05, 7.302846283510345e-05, 0.0003026562933701, 0.0005652528304066, 0.0006442890214048, 0.0005624012226613, 0.0004041625489588, 0.0003221702234206, 0.000277933001405, 0.0001616595450271, 3.244009537725218e-05, 7.711345319842871e-05, 0.0004045214674428, 0.0007284096939287, 0.0008690217345724, 0.0008503125069596, 0.0012084148611278, 0.0029619652044286, 0.005358499112823, 0.0063419861681003, 0.0048110203624607, 0.0022126412512958, 0.0006247713889745, 0.0003637338717507, 0.0003727805697888, 0.0003365519862412, 0.0002158048420558, 0.0001053771411613, 8.566681732347914e-06, 0.0001383864806835, 0.0005177134463723, 0.0009108935120972, 0.000900868527853, 0.0004997611532554, 0.0001830029625271, 0.0001570169651742, 0.000286928057852, 0.0004466009670752, 0.0005151048402354, 0.0006931751296257, 0.0018343915614746, 0.0033524549938763, 0.0029547287342922, 0.0032478353836895, 0.0016752584090115, 0.000704256653363, 0.0003566137631471, 0.0002718427830085, 0.0002314380341087, 0.0002151330571117, 0.0001360323275891, 3.029541433889213e-05, 3.1077205582798304e-05, 0.0002065409332069, 0.0004684509591165, 0.0005300206728983, 0.0004599249147694, 0.0003396389610337, 0.0002583398587425, 9.1468641880845e-05, 4.981626566352625e-05, 0.0001961028916128, 0.0003007068671852, 0.0002467404353204, 8.6338058277564e-05, 6.11332750997963e-05, 0.0001828787500978, 0.0003218354264863, 0.0003758323212673, 0.0003110434261072, 0.0001629957771843, 7.66872825208218e-05, 8.098986450812232e-06, 6.013341449501336e-05, 0.0001872451039897, 0.0001992002048472, 0.0002266540631843, 0.0001983001410921, 0.000237732578775, 0.0003058525902207, 0.0002690445522798, 0.0004350734060526, 0.0006534903511419, 0.0015800968265409, 0.0030282676999258, 0.0035774742946349, 0.0026493223455863, 0.0010557530587089, 0.0001242820664246, 9.033374207836636e-06, 0.0001319403608516, 0.0002726479853037, 0.0002868313852443, 0.000251815781334, 0.0001438810062885, 0.0001244723869873, 0.0004186828729921, 0.0008516576397655, 0.0009711246993442, 0.000556088645689, 0.0003496555515673, 0.0001285924592231, 2.960388711467479e-05, 9.070852831593234e-05, 0.0005323883532651, 0.000875678823437, 0.0008544213124132, 0.0004339166241466, 0.0001968286502441, 0.0002905197559275, 0.0003824883201763, 0.0003467339246523, 0.0002369530255299, 0.0001274143165132, 1.867398294462917e-05, 1.6910237236151718e-06, 7.986839532537191e-05, 0.0002531653391432, 0.0003318797812082, 0.0002902402806692, 0.000190923853561, 8.93949765269769e-05, 0.0001408943330579, 0.000181811084836, 0.0001577489002709, 6.41683494198407e-05, 2.07307422203148e-06, 6.329396855581467e-05, 0.000201181345579, 0.0002698099088118, 0.0002939566570453, 0.0002322772328491, 0.0001570017087969, 0.0002382170194582, 0.0002505927036402, 0.0002455616566908, 0.0001551949341731, 2.756312191938197e-05, 7.299377471247376e-05, 0.0001197840863181, 0.000133995024893, 8.87447682068272e-05, 8.883016088199515e-06, 9.4591616607279e-05, 7.74813647821934e-05, 0.0001235787802195, 0.0001044768635727, 5.5753608066935406e-05, 0.0001493525009261, 9.83467378750934e-05, 0.0001060959610129, 1.545401697316819e-05, 8.51088503290192e-06, 1.549302115218545e-05, 5.258124150832869e-05, 2.9836207794610895e-05, 2.347800016658152e-05, 4.650399718407805e-05, 2.7345138656399627e-06, 5.704721716626899e-05, 0.0001165040869353, 0.0001181002854715, 5.130973572141063e-05, 1.1939672646580153e-05, 9.456905204541408e-05, 0.00012758838067, 0.000261024254379, 0.0003450450846516, 0.000349888866456, 0.0002341192562389, 3.424745534478476e-05, 0.0001348729780688, 0.0006444067911878, 0.0007926174225277, 0.0010571616766345, 0.0007032781063848, 0.000374790824522, 0.0003188412912818, 0.0003280682278641, 0.000702805691963, 0.001954208440166, 0.0025326547240437, 0.0044091505334406, 0.00411047900377, 0.0026558617951236, 0.0012109532910901, 0.0004314492747062, 0.0003188663781043, 0.0002965264394702, 0.000566894514063, 0.000808567918183, 0.0009568731587198, 0.0010998368095357, 0.0012307366571527, 0.001819882127446, 0.0031212790027384, 0.007793600283592, 0.0102166112253749, 0.0083971854452637, 0.0038773571257153, 0.0007660043296513, 8.99635357985174e-05, 0.0002715045681983, 0.0007641807560401, 0.0009788244726622, 0.0007348018537483, 0.0001794496634911, 0.0001788404874457, 0.0013852566817179, 0.0020529650870927, 0.0032070946044315, 0.0023041927778134, 0.0008855287951704, 0.000209019245298, 0.0001772751568822, 0.0002664910011747, 0.0006083068422772, 0.0008771472236642, 0.0007681536407828, 0.0004047782939957, 0.0003660668961552, 0.0005438119886631, 0.0011524781169988, 0.0011548959788058, 0.0006236207147713, 0.0001634452355203, 4.356727617502196e-06, 1.9203953761859352e-05, 8.655232085481569e-05, 0.000242673520077, 0.0003868119715691, 0.0002722161090826, 7.771123308426667e-05, 1.7347245093370643e-05, 0.0002390640615256, 0.0004584527921404, 0.0004583139493123, 0.0002860884761226, 0.0001033332740923, 0.0003678963342386, 0.0007833286672649, 0.0009703778050723, 0.0007645481292997, 0.0003968081336597, 0.0001336454357274, 3.6548893880481945e-05, 1.0426489829293996e-05, 5.924788130608502e-05, 0.0001791517432886, 0.0001254637377705, 7.68794626392441e-05, 5.29791652525572e-05, 0.000138562800704, 0.0004321097495722, 0.0004351513391741, 0.0005392564691017, 0.0002954871105561, 4.8978662394746615e-05, 3.119800622858596e-05, 0.0001116707197555, 0.0002780439105936, 0.0003078370273392, 0.0002498467728707, 0.0001959198870877, 0.0001194602023499, 0.0001164016471517, 0.000105155092114, 0.0001353818787606, 0.0001448326259588, 4.830039721415081e-05, 9.34712588180556e-06, 1.5777725097570428e-05, 0.0001190147461081, 0.0002089483861678, 0.0001687029201964, 0.0002033145142101, 0.0001578833665175, 0.0001305963342457, 0.0001128171303749, 0.0001718113767192, 0.0003211963525778, 0.0003396235836278, 0.0001749294980785, 3.398968402984786e-05, 1.4805897061053008e-05, 3.9765996189176393e-05, 0.0001471620112782, 0.0001491038911495, 0.0002460105832346, 0.0008430991932117, 0.0014859015475815, 0.0015875902549875, 0.0008300419326422, 0.0004817063241819, 0.0001241733207186, 4.8027539418508e-05, 8.841884990195619e-05, 0.0001614349040595, 0.0002750276990964, 0.0002037321007265, 5.006274472961791e-05, 1.1063118660164625e-05, 0.0001897139779518, 0.0003574235566847, 0.000337206789872, 0.0001406575670662, 5.058632880386308e-05, 9.10847726241374e-05, 0.0001391894159083, 0.0001723872326659, 0.0001056804855353, 0.000147812995123, 0.0001433998702338, 0.0001330802778884, 0.0001908097911327, 0.0003417514663608, 0.0003533415117709, 0.0003103907583171, 0.0001780612808535, 0.0001724589413885, 8.214918345573341e-05, 1.82509566674014e-05, 7.84932050368175e-05, 0.0002293841929065, 0.0002826791814188, 0.0002790124207018, 0.0001278902200789, 0.0001666164618255, 0.0001839319712743, 0.0001841836137999, 0.000126927238531, 9.694791682342847e-05, 0.0001107989484011, 6.31263452814859e-05, 3.4260417119624404e-05, 4.889868511428879e-05, 1.5239356179533876e-05, 6.494698705088883e-05, 8.070519523048589e-05, 0.00018520445517, 0.0002435375963182, 0.0002044593893179, 0.0001270983358559, 0.0001090051713593, 2.6221130681839284e-05, 6.50980009630492e-06, 6.391217740873222e-05, 0.0001233543604673, 0.0001273100771984, 8.08757570350796e-05, 7.58551048376533e-05, 3.230226837971116e-05, 7.29919672631664e-05, 8.83370122994779e-05, 0.000130906240779, 7.294598525161075e-05, 1.302110292427286e-05, 0.0001004856994552, 0.0002128243684964, 0.0002703349388707, 0.0002298566771581, 0.0003961260803113, 0.000595714456917, 0.0006008559765165, 0.0003133158324991, 0.0002033502341828, 6.60734434503175e-05, 4.0163199619094896e-05, 7.32195711350579e-05, 0.0001049572069835, 0.0001036502379832, 4.1508838486308776e-05, 3.601457021731177e-06, 2.874902593461394e-05, 7.981782070842101e-05, 0.0001191257836357, 0.0001312463827924, 8.85162615166179e-05, 9.77151616365276e-05, 0.0001715833738766, 0.0001387757246964, 0.000119185178452, 7.93377466282271e-05, 4.052025225930424e-05, 2.605859217608884e-05, 1.645283657577551e-06, 4.121335016429822e-05, 0.000118294786607, 0.000112842811913, 4.608381550113254e-05, 2.096964132047792e-05, 6.54188053237942e-05, 0.0002161616196183, 0.0002207750980768, 8.71166982944352e-05, 2.827892860751961e-05, 5.624708711705567e-06, 3.866542624347958e-05, 1.980106331310988e-05, 8.27696679755954e-05, 0.0001189885735942, 1.8690280665050268e-05, 1.446044208218502e-05, 1.855374030980943e-05, 5.05443947378219e-05, 0.0001249383077442, 5.403773923365203e-05, 0.0002277534970297, 0.0003592171975861, 0.0006587931043132, 0.0005762721557031, 0.0002608167827284, 0.0003196572091803, 0.0003634838033115, 0.0002529920859554, 0.0002450605612135, 0.0002946919928103, 0.000355904425367, 0.0005772857045209, 0.0005573502654646, 0.0004239412355472, 0.0011291435035787, 0.0023388528786658, 0.0023230039472284, 0.0029255225168736, 0.0018957381783122, 0.0008021663695705, 0.0006942567087226, 0.0005269137718885, 0.0002962588662152, 0.0003303398935404, 0.0002586873854629, 6.16434233654437e-05, 1.0167746912159073e-05, 0.0002100493430485, 0.0003782066093166, 0.0007000938194412, 0.0005827776977666, 0.0002843463347362, 0.0002052747479441, 5.412183509514429e-05, 4.36052944489738e-05, 8.09414205379665e-05, 0.0002077787760202, 0.0001980464937093, 0.0001674262819156, 7.49743392400261e-05, 5.15271631132763e-05, 0.0001657089200212, 0.0003111211620791, 0.0002834518553432, 0.0003408025546208, 0.0002350358898428, 7.15866421513356e-05, 1.6487507870530454e-05, 4.40628783784996e-05, 0.0001017833122318, 0.000200977838209, 0.0001634284941622, 6.43599893935773e-05, 1.562821635880771e-05, 3.235177143808116e-05, 6.75334264012277e-05, 0.0001170136141859, 0.0001162512718874, 4.895952639141577e-05, 4.024327754603727e-06, 1.37320371193773e-05, 5.197695947483623e-05, 0.0001374690518372, 0.0001404569267672, 0.0001206022997828, 8.778267078407571e-05, 2.92754963563562e-05, 2.9660809112053e-05, 0.0001459784539815, 0.0001448999116243, 0.0002910486192936, 0.0002472044526286, 0.0002506683436946, 0.0001279240216856, 9.23528481669658e-06, 2.727409662289367e-05, 0.0001392587092958, 0.0001830906803243, 0.0002245155597689, 0.0001201705792465, 3.3644697497379486e-05, 8.81928804531503e-06, 1.800402929798233e-05, 7.978920592557602e-05, 0.0001529036461124, 0.0001037592309616, 8.93852124838688e-05, 2.815006366320864e-05, 2.5160589652218846e-05, 7.95446604632696e-05, 9.04802501412865e-05, 0.0001954162022756, 0.0004015498602097, 0.0004489250251183, 0.0007139654905901, 0.0006775996487167, 0.0003528282122474, 0.0002950338301931, 0.0001529885806103, 0.0002137001564061, 0.0002295139240089, 0.0001560815947371, 0.0001552175779227, 9.00076951699522e-05, 0.000107612299428, 0.0001283942229777, 8.13929442821531e-05, 4.478048977440544e-05, 4.044374322135639e-05, 0.000103016222324, 0.0001743190789828, 0.0001235114340972, 0.000131529391033, 0.0001271968260091, 0.0001808859175416, 0.0002636782077974, 0.0001802795062759, 0.0002660377196567, 0.0001938870651901, 8.50515116455116e-05, 3.823245278816102e-05, 1.12066999568816e-06, 6.865267795404305e-05, 0.000136941318699, 0.0001174751677495, 0.0001870014301563, 0.0001260802269364, 0.0001860342850432, 0.0001585467424659, 2.6637452796277306e-05, 1.770997500067459e-05, 4.17628971607146e-05, 0.0001405742848645, 0.0002744113010231, 0.0001887467492801, 0.0001732064978464, 9.58032090221914e-05, 5.433132154315708e-05, 5.2318337060367176e-05, 7.795433308214839e-05, 0.0001119321095662, 0.0001015223563035, 0.0001617631772097, 0.0001515919482073, 0.0002168323296023, 7.93217415924584e-05, 1.190323197162332e-05, 1.7113013006464602e-05, 0.0001148279342889, 0.0002328096854835, 0.0001309103911308, 0.0001058824687058, 0.0001157721062725, 8.59885321010999e-05, 0.0001040110125902, 3.258805860050306e-05, 0.0001092826261064, 0.0001550569189581, 0.0001001988067389, 7.88674185949388e-05, 3.314777352550366e-06, 7.510992561633356e-05, 7.871926506251121e-05, 0.0001810901199307, 0.0002504730917354, 0.0001419116368291, 0.0001182760761248, 1.883091400812932e-05, 3.442012905066356e-05, 0.0001103330690621, 0.0001716184189462, 0.0001260567162579, 3.201041310348501e-05, 5.269202797651114e-05, 0.0001120266065859, 0.0001507550601223, 8.56595481855845e-05, 8.0776590359626e-05, 9.05704737651324e-05, 0.0001056491017272, 0.0001469954436569, 9.12590835948489e-05, 5.270726936186537e-05, 1.0135286097274173e-05, 3.849237900714629e-05, 0.0001040187439188, 0.0001885304457168, 0.0001418984638772, 0.0001648560216614, 0.0006300174726224, 0.0009149648041896, 0.0014098546528467, 0.0008302681191375, 0.0005911150034086, 0.0001629412185889, 0.0001760871975314, 0.0002000980993834, 0.0001350340629157, 0.0001418158003351, 5.46826779367562e-05, 5.826924373774464e-05, 3.7347544734115664e-05, 0.0001143032652888, 0.0001264731924808, 0.000167696370713, 9.04514646147732e-05, 4.734658487811869e-05, 6.4215127990949e-05, 0.0001166439051188, 0.000415628145672, 0.0005257769720126, 0.0008046468002471, 0.0004857033733564, 0.000348813615375, 0.0001043348827922, 0.000106923423327, 0.0001003483406373, 0.0001243531112468, 7.392401017779842e-05, 3.170554514341499e-05, 7.552365294031061e-06, 6.168031819360432e-06, 7.45368553066516e-05, 9.077906899383292e-05, 0.0001288833235868, 7.74002254112423e-05, 7.18345659787818e-05, 6.505613198941641e-05, 0.000161267817795, 9.999985680510792e-05, 0.0001080498981518, 2.525646877775747e-05, 1.055278361708335e-05, 2.958153265132505e-05, 0.00013517779166, 0.0001785490499062, 0.0001250636774039, 0.0001419658940072, 0.0001113196715307, 0.000171810916929, 0.0001222397551692, 0.0001229012392677, 7.104683252423199e-05, 0.0001257286309062, 0.0001201301054572, 0.0001890849500156, 0.0001510118825967, 0.0001738731060698, 0.0001590980396949, 0.000160157834572, 9.87261209199131e-05, 7.256313006786615e-05, 8.92588921226905e-06, 4.8187110278620055e-05, 7.29658188154798e-05, 0.000136195930647, 0.0001066879903481, 0.0001412590066613, 9.17343384381784e-05, 0.0001127661342375, 9.46429143007756e-05, 0.0001020410612545, 7.61255090636129e-05, 0.000147435656296, 0.0001264230131911, 0.0001170747535354, 4.209605905433402e-05, 1.723288868823249e-05, 5.9066409285145495e-05, 6.15862670095952e-05, 9.64953049579916e-05, 5.913177104307981e-05, 4.307534683577208e-05, 6.770624903559071e-05, 0.0001388062115713, 0.0001528197382951, 0.0001943714560355, 0.0001184087235031, 0.0001642293042814, 0.0001479926897802, 0.000152054224305, 2.8799353216373952e-05, 7.75921997413415e-06, 7.988868919941399e-05, 9.84748442457387e-05, 0.0002014947828867, 0.0001333890551896, 0.0001100508938126, 4.434630345291733e-05, 1.105320341057461e-05, 1.727946989921869e-05, 8.34880968744161e-05, 8.87496260944225e-05, 0.0001010982671587, 4.41170454830069e-05, 1.2294523995734304e-05, 2.369385312882583e-05, 0.000109631174995, 0.0001056715738535, 0.0002011756215053, 0.0001029802675043, 0.0001005559159783, 8.49495427609654e-05, 0.0001058491235543, 0.0001179373303836, 9.06675920003182e-05, 4.71552324886868e-05, 3.448955352439367e-05, 6.27014004170361e-06, 5.3645390493931006e-05, 4.08993195269707e-05, 8.123840505590529e-05, 8.87165642818133e-05, 0.0001452435807415, 0.0001421505714086, 0.0001544655879143, 0.0001956234994612, 0.0001048216495752, 0.0001085720875388, 2.2753477811840672e-05, 2.745860589991397e-05, 6.27354631344123e-05, 0.0001218807690948, 0.0001007864921459, 0.0001368300556737, 6.02850170326988e-05, 0.0001094009156756, 0.0001006244237001, 0.0001521152941818, 9.29983197631304e-05, 3.8195216444159805e-05, 4.695216237412128e-05, 0.0001238451111626, 0.0002314937462293, 0.0001676800686032, 0.0001222997531659, 1.766443322097114e-05, 8.840888202972069e-05, 9.13366736349609e-05, 0.00011950639893, 3.595409357072226e-05, 8.353969761703507e-06, 3.381260168700612e-05, 6.060356707569531e-05, 4.51997948988872e-05, 1.906267098809605e-05, 7.472117996451301e-06, 2.700075202627765e-05, 6.412000503187959e-05, 7.0981554707599e-05, 0.000153093653796, 0.000135911939656, 0.0001738279486926, 0.0001505950331983, 0.0001700476963183, 8.930094875507711e-05, 4.19101214973995e-05, 3.9929545887634185e-05, 2.78788756320101e-05, 5.9782083102022095e-05, 6.82784557859222e-05, 6.21510268491459e-05, 0.00011143455618, 0.0001659428226625, 0.0001049194025963, 0.0001244520076126, 0.0001389807189511, 0.0001035190911566, 0.0001571484492955, 0.0001397753405822, 0.0001985320652881, 0.000114903374888, 7.458121474582888e-05, 2.67563006082571e-06, 1.253139358545329e-05, 8.18967322820414e-05, 0.0001016764844065, 0.0002253694846973, 0.0001922757360126, 0.0001878435426644, 3.5210950042263775e-05, 1.087930267337229e-06, 6.106345788752494e-05, 0.0001216111113934, 0.0002235926044856, 0.0001361031760295, 9.14389812686253e-05, 3.99588142294247e-05, 3.9017363592092e-05, 4.249150444450716e-05, 5.3749859613743295e-05, 5.46675678091557e-05, 6.33981532414073e-05, 0.0001389104403227, 0.0001583934174566, 0.000166760745704, 0.0001789841387567, 6.88522418264043e-05, 2.440635413822736e-05, 3.808703925076183e-05, 0.0001131977105324, 0.0001076559086414, 9.793232862459007e-05, 5.990434297881642e-05, 8.65113244376262e-06, 5.911310640322318e-06, 1.18931597655176e-05, 4.360413462276136e-05, 2.470926836369408e-05, 2.760009890388047e-05, 0.0001102452921484, 0.0001209710738284, 0.000192572045641, 0.0001326784468988, 0.0001144785734826, 0.000131172431194, 7.86979456937669e-05, 8.755396991967159e-05, 7.759771844865469e-05, 0.0001267653671586, 0.0001240144300866, 9.98346201449053e-05, 8.386237116392729e-05, 2.272590941312307e-05, 6.23556846216239e-06, 1.0744333674896428e-05, 6.126614940214015e-06, 2.4145854928953545e-05, 1.742875009418736e-05, 5.360425391995324e-05, 5.0437570786116605e-05, 3.04577121430271e-05, 5.590219845369279e-05, 3.54092166041716e-05, 1.549768479387169e-05, 2.909591460502648e-05, 2.189129131834989e-05, 3.01504509279858e-05, 2.277562717152443e-05, 2.880098066847028e-05, 3.4225385663032764e-05, 7.146497190316101e-05, 0.000109705919179, 7.73864848076726e-05, 5.0960152075266896e-05, 2.804934495253988e-05, 3.167871970637413e-05, 9.99962857239267e-05, 0.0001054330934472, 0.0001929754702326, 0.0001825944546498, 0.0002472360766854, 0.0004023403459898, 0.0003173418004316, 0.0004100473902244, 0.0005164279485704, 0.0010677057877724, 0.0022797600636921, 0.0019230627491548, 0.0020479834818718, 0.000762728908719, 0.0002966722220999, 0.0001232173970082, 8.83128643204898e-05, 0.0001661640043108, 0.000281564704314, 0.0001882514440849, 8.081844317424151e-05, 4.874633895220961e-05, 0.0001473549976109, 0.000392035295922, 0.0003689045542388, 0.0003955819048648, 0.0001283352695519, 4.671901023383438e-05, 1.888628542920929e-05, 5.43287457933666e-05, 0.000128503999272, 0.0002440425259453, 0.0001940415494004, 0.0001864260172685, 0.0001300058713475, 0.0001709027281248, 0.0002661154102419, 0.0002115395824476, 0.0001613044400067, 0.0001073780704642, 3.3097898417983466e-05, 3.787593431576734e-05, 7.491943441062659e-05, 6.51943970216493e-05, 1.6503371340660662e-05, 2.233711713550191e-05, 3.813833926849216e-06, 7.139788823508396e-05, 9.454823019529318e-05, 0.000114324956531, 0.0001137902860746, 8.56354786395434e-05, 8.93999678661071e-05, 2.6473237527102583e-05, 1.808212858895424e-06, 3.5012863300612566e-05, 5.7969655637649207e-05, 8.431647614195269e-05, 0.0001539544872789, 0.0001193513292143, 0.0001193977101971, 5.73190904916977e-05, 5.82789073547029e-05, 7.92271817590162e-05, 7.41491830071777e-05, 9.82739672891842e-05, 0.0001418729159037, 0.0001153294577238, 0.0001205526214174, 0.0001992473379489, 0.0001944839363547, 0.0002215034233128, 0.0003291153766483, 0.000167151681987, 0.0001376112917048, 2.829837967361425e-05, 1.25668219906175e-06, 2.784858864813996e-05, 6.92604116399709e-05, 9.4131875598186e-05, 0.0001711691686063, 0.0001478735232529, 0.0001394987814893, 0.0001363463638392, 3.270604203240259e-05, 1.6804165479664202e-06, 2.815589845282452e-05, 1.4020293662085773e-05, 1.740827852520411e-05, 2.575037005934593e-05, 1.852903618507855e-05, 7.5461585886984e-05, 0.0002287227349869, 0.0001965525022202, 0.0001704272854459, 0.0001876898568556, 9.79327403657868e-05, 0.0001608585096029, 0.0001660381019504, 0.000229357409083, 0.0004362390530716, 0.0003669654514965, 0.0003848973028492, 0.0004688643586314, 0.0004374802977762, 0.0007557980313215, 0.00154743928948, 0.001354148704997, 0.0012014900537774, 0.0009648754662499, 0.0002694331205585, 0.0001314309216403, 8.29724005931813e-05, 9.10788398769295e-05, 9.31279517764349e-05, 0.0001089090824365, 6.19879299902134e-05, 6.019707685171869e-05, 0.0001342431169629, 0.0001707797323762, 0.0001485345786114, 0.0001170219466913, 2.631630720800631e-05, 1.067993619227234e-05, 8.74595320704904e-05, 7.34178222514313e-05, 6.53083848598914e-05, 5.5213021647203e-05, 2.545483555377192e-05, 3.2147131435012697e-06, 3.125119943849915e-05, 0.0001561194673016, 0.0002117941668805, 0.000241685561725, 0.0002828419686474, 0.000120438652408, 6.84980072980052e-05, 2.1149788971246933e-05, 2.057130288251241e-05, 8.65857791928079e-05, 0.0002003195790147, 0.0001522520973992, 0.0001404197101864, 8.6583289067298e-05, 7.96580917245442e-05, 0.0001183827986317, 0.0001908657359831, 0.0001018251352706, 5.41085589475344e-05, 2.699289401126118e-06, 2.1447982004916785e-05, 6.49436238816261e-05, 0.0001180588398783, 0.0002000317483229, 0.0001667565522195, 0.0001689349179566, 0.0002192677806846, 0.0001273856151623, 5.507545632487803e-05, 1.2164818090348588e-05, 1.07851301077025e-05, 4.9193203398130297e-05, 0.0001283053690422, 8.891151436642268e-05, 3.790192556152756e-05, 3.3749671396326696e-05, 6.87360716617627e-05, 2.491999254410772e-05, 6.20529472536249e-06, 9.49355656760176e-06, 4.591165663810522e-06, 7.822205953352909e-05, 0.0001654200081509, 0.0001244214246973, 0.0001353645145383, 9.97195326088884e-05, 5.92884047150487e-05, 3.7762754383836495e-05, 1.295521138467954e-05, 4.789191448027716e-05, 3.137519075229232e-05, 3.607527607505791e-05, 8.36970654024306e-05, 7.33646020688222e-05, 6.64899220147198e-05, 6.2638196908015e-05, 6.90058530915515e-05, 2.7436659680537456e-05, 3.2988714203658e-05, 2.631610760855156e-05, 2.438583649213779e-06, 1.130637515020596e-05, 4.5558096660318096e-05, 0.0001017183662962, 0.0001196170291255, 0.0001252828092275, 0.0001274039011128, 6.04545114004806e-05, 5.12281087306365e-05, 3.90046350063843e-05, 9.05949767439963e-05, 9.164215621922948e-05, 7.95007780533257e-05, 4.487888042796534e-05, 1.840179494639067e-06, 8.000119135838975e-06, 3.118851676100535e-05, 8.667611411936681e-05, 9.81494281394523e-05, 9.95040089537947e-05, 0.0001314682286184, 7.69602681418492e-05, 6.66970614072117e-05, 4.4279330168494095e-05, 1.103973706694627e-05, 1.930669211342847e-05, 6.295087748449559e-06, 5.6628370029671496e-05, 5.8502380044504605e-05, 1.777772906791037e-05, 7.535625891815265e-06, 3.046167418790113e-05, 3.444768992107919e-05, 7.61056682014437e-05, 8.600457628848621e-05, 0.0001072716325078, 5.98872157648123e-05, 2.52016512596358e-05, 4.201084589644275e-05, 3.859710839232959e-05, 4.45542305521299e-05, 2.301368137925203e-05, 3.096627967893115e-05, 3.490348655352984e-05, 3.63570871407888e-05, 1.868813550933294e-05, 7.019569418748269e-06, 0.0, 1.0435182641016888e-05, 3.773077832419967e-05, 0.0001040964535168, 0.0001167420141149, 0.0001631611177714, 0.0002364084095629, 0.0001864051272459, 0.0002155901411439, 0.0002705272710369, 0.0004296899407575, 0.0004479741902632, 0.000551824012839, 0.0006303859640713, 0.0008622911732024, 0.0005766487889612, 0.0008059904184229, 0.0016516076765228, 0.0039881120455135, 0.003777965104054, 0.00344553607067, 0.0023455147066766, 0.0013326371249742, 0.0002968314529413, 0.0001985414277506, 0.0002755313769966, 0.0005788636261489, 0.0005615477536011, 0.0005433213216366, 0.0005234988454744, 0.0007942255916243, 0.0007055522411466, 0.0007086437723354, 0.0005563870892772, 0.0003291964579153, 3.415316183486152e-05, 1.4999471037303882e-06, 3.530327898909257e-05, 0.0001990094710553, 0.0002675434806737, 0.0003081801491893, 0.0002897469417001, 0.0003262048777331, 0.0002872531990491, 0.0003582724755137, 0.0003956332888287, 0.0004991392194531, 0.0002808890030391, 0.0002199087491891, 0.0002253932504102, 0.0004279855876719, 0.00040976448987, 0.0004018537006582, 0.0002985439388512, 0.0002114095424912, 8.987435779320689e-05, 9.523424402062293e-05, 9.304383944944549e-05, 0.0001150932091915, 3.97596306018815e-05, 2.265350708213495e-05, 9.929101300483e-06, 3.6402814351726747e-05, 0.0001460023110568, 0.0001223904754183, 0.000106829591485, 7.028432387968699e-05, 8.87711210347101e-06, 4.011830504993991e-05, 6.700900215906081e-05, 6.899956241533331e-05, 9.77602911272583e-05, 3.737020122644072e-05, 3.37785616670226e-06, 1.21265128368702e-05, 4.716816287796133e-05, 0.0001506615893888, 0.0001640488768819, 0.0001493375030368, 8.765465611503979e-05, 2.0358922353245837e-05, 2.0221286971278388e-06, 2.347535664553091e-06, 2.572201882795344e-06, 3.9419324227975776e-05, 6.02212814275444e-05, 6.540794498216911e-05, 9.30909733966984e-05, 9.75690778341744e-05, 8.5780905337868e-05, 4.50809288171879e-05, 3.429426696914446e-05, 4.893460119154564e-06, 3.95233962246146e-05, 0.0001689795057671, 0.0001956846401216, 0.000257683969586, 0.0002395864348553, 0.000241780842447, 0.0002551580035174, 0.0004745367856627, 0.0008104560146265, 0.0010065217404267, 0.0012227234450262, 0.0005630292108591, 0.0002316356326196, 6.63636439018837e-05, 0.0001209169625493, 0.0001463159932167, 0.000191121440856, 0.0001982652030996, 0.000170315128174, 0.0001463849673306, 0.0001360854332548, 0.000193988485692, 0.0002393425723249, 0.0002372467563192, 0.0002105343638491, 3.640020628334482e-05, 1.7061541477661704e-06, 2.333315047445976e-05, 7.97452033760631e-05, 0.0001898295886525, 0.0001742156343814, 0.0001774912368433, 0.0001651309584287, 0.0001536535443995, 0.0001645276667167, 8.400254246392771e-05, 5.54065553041755e-05, 6.21898148134766e-05, 6.29363963854341e-05, 0.000106998843407, 5.0802216105217806e-05, 3.71521177828405e-05, 3.6328604516789e-05, 4.00008655974294e-05, 9.259882389623607e-06, 3.517625071674381e-05, 6.99843157229039e-05, 9.43052167035344e-05, 0.0001126746304419, 0.000123765770828, 3.536964904168638e-05, 3.7799622199407903e-05, 3.57360247409439e-05, 2.048020828949519e-05, 5.414985126873407e-06, 2.696543424659933e-05, 2.073686970473717e-05, 1.674572205471587e-05, 3.40185740011572e-05, 4.562980205835183e-05, 6.56620280735921e-05, 7.21330381201141e-05, 2.7830954487194133e-05, 2.5535593621603545e-05, 6.59716191901898e-05, 0.0001064044741025, 0.0001534517524408, 0.0001136971154228, 9.15140210660487e-05, 9.596673073482848e-05, 0.0001152591112146, 0.0001117251183936, 9.669923108328908e-05, 7.21592050392192e-05, 6.7861129395756e-05, 6.51328731878629e-05, 3.74843306608356e-05, 5.377435169436359e-05, 9.57211868923394e-05, 0.0001584465697926, 0.0001657804965607, 0.0001606808494329, 0.0001131052538367, 0.0002034065882508, 0.0003706201494142, 0.0005182529629092, 0.0007550349418773, 0.0004185046253547, 0.0002597042536636, 0.0001505029919242, 9.478556092497792e-05, 6.40175539657407e-05, 7.42131822469672e-05, 1.142268791305953e-05, 1.6268586327446122e-06, 1.4414089945889373e-05, 4.61327217119318e-05, 7.261357496672319e-05, 0.0001334395283811, 9.886131733967028e-05, 5.96643110129155e-05, 2.8084175322266115e-05, 3.036650468092999e-05, 8.876685542709289e-05, 0.0001365975925448, 0.0001690949326925, 0.0001749883082768, 0.000160514299292, 0.000159916875185, 0.0002655932278247, 0.0002208034026764, 0.0002217541033582, 0.0001841576233947, 0.0001186802853432, 6.782867774402331e-05, 5.63401783794683e-05, 4.12053885491384e-05, 7.42667186756289e-05, 8.14327725965712e-05, 0.0001081261680784, 9.66678691023103e-05, 6.28287403342252e-05, 4.683188315303414e-05, 2.6835401822473304e-07, 1.715377952769803e-05, 6.56016524615609e-05, 8.583887813774701e-05, 0.0001032629531927, 0.0001230274870824, 8.30307178304004e-05, 9.99904183103618e-05, 0.000105961309109, 8.11430557081854e-05, 4.148888694226388e-05, 1.472599695458292e-05, 6.273377284869638e-06, 1.3365747985345569e-05, 5.56495301400284e-05, 6.32756322800662e-05, 4.920629016919519e-05, 5.5552964823238406e-05, 9.04750439420253e-05, 8.464515773498459e-05, 8.81266978441284e-05, 6.35583662026319e-05, 3.208785207761342e-05, 1.048339344694554e-05, 6.29613229955746e-05, 9.32699564358917e-05, 0.0001111051167272, 0.0001065220345609, 9.43836818343064e-05, 5.48861874806383e-05, 2.216197959712376e-05, 1.744561565890129e-05, 5.85945094822681e-06, 2.1172820274317173e-05, 6.44725443384445e-05, 0.0001269967377945, 0.0001909613343749, 0.0002044068669356, 0.0002275481638161, 0.0001014735446286, 3.062126869624569e-05, 5.32510685140614e-06, 1.28238645525308e-05, 1.219886464593846e-05, 4.7222093653881e-05, 2.535349975680872e-05, 1.9361504923764712e-05, 5.71226114128553e-05, 9.405452078206152e-05, 0.0001218437736546, 0.0001092782971698, 5.528100341764311e-05, 5.38405644671372e-05, 2.245187065772077e-05, 2.9198704121409298e-06, 1.632423139118294e-05, 1.6577654366758703e-05, 2.955792815499316e-05, 6.13458999567562e-05, 4.915285281359549e-05, 9.58898245034597e-05, 8.95375234873882e-05, 6.60651691077245e-05, 5.639049328686519e-05, 6.398364541341801e-05, 4.2457600424572505e-05, 6.03381504414834e-05, 6.264610005453498e-05, 1.153713062396618e-05, 3.102910527476779e-05, 2.650953308834521e-05, 3.700574539497818e-06, 1.404103870591895e-05, 1.952080223290357e-05, 1.6499153414368532e-05, 5.09764084052027e-05, 1.9371054657587912e-05, 2.0374217542005906e-05, 7.503407004788329e-05, 0.0001269603429762, 0.0001987540167208, 0.0002741440181838, 0.0003129955654891, 0.0004449240252717, 0.0004408666255932, 0.0005672983102656, 0.0007165148448857, 0.0008378949884319, 0.0008851994569618, 0.0008172202759027, 0.0006963953195177, 0.0005079817475105, 0.000374687798952, 0.0001190890750266, 3.304763484852235e-05, 3.57796446994761e-06, 1.174419924561536e-05, 3.937259635848042e-05, 0.0001051752425027, 0.0001681270402333, 0.0002309031348531, 0.0001220968562361, 6.80937739331451e-05, 2.650562441848467e-05, 1.044263257743396e-05, 1.2001111073718102e-05, 5.48721767008831e-05, 8.197807386609181e-05, 0.0001112269721396, 0.0001641127855162, 0.000106957433951, 7.58172610143293e-05, 6.55051653112282e-05, 6.702929551781711e-05, 7.25381862393758e-05, 7.69873333497291e-05, 6.507643445648141e-05, 7.16912278141718e-05, 3.273720449954159e-05, 1.316722254970694e-05, 3.332764153522168e-05, 3.699333464936751e-05, 5.54017688702833e-05, 0.0001104529755706, 9.7728841468413e-05, 6.693750807786389e-05, 5.68292825486209e-05, 3.096652086010617e-05, 0.0001190802049841, 0.000154311507952, 0.0001614764188793, 0.0001293616376777, 9.18326719533996e-05, 7.07241106928407e-05, 5.2063946003008695e-05, 1.7243863181189294e-05, 8.43120413562122e-06, 3.057175051560467e-06, 3.978300712935319e-05, 4.22080283854585e-05, 4.9446194713976e-05, 7.70194258514006e-05, 0.0001081540931782, 0.000115547568147, 9.5764156686265e-05, 7.89043485102827e-05, 5.84242784612766e-05, 4.59220168714083e-05, 7.596760247999588e-06, 8.12868075479975e-06, 2.56138141273653e-06, 3.139450895307962e-05, 2.8337526348438735e-05, 2.212692445719583e-05, 6.519811697209034e-06, 5.324326567194239e-06, 3.313524694258208e-05, 6.27143528526289e-05, 5.12788786402608e-05, 6.0466382338277697e-05, 3.439057521534444e-05, 1.909012787557498e-05, 4.1200985204713e-05, 3.41885429179528e-05, 3.777234547525997e-05, 7.55363591852205e-05, 8.64509023148059e-05, 9.07729623367818e-05, 6.288415165023201e-05, 3.64488696729297e-05, 5.35453141976559e-05, 6.35802192618225e-05, 6.08495971379913e-05, 4.2765682160816415e-05, 1.881802643087925e-05, 4.174406383077426e-05, 5.90560961700355e-05, 5.34185111805738e-05, 6.9002230961589e-05, 5.80500015028139e-05, 1.253237522963778e-05, 1.210408097412676e-05, 4.97530713551889e-07, 9.18738087285551e-06, 2.076059990488759e-05, 6.34170083673015e-05, 5.743496590949299e-05, 4.527995892399309e-05, 8.583884021100489e-06, 3.37493909669379e-06, 2.333188361261821e-05, 8.05423491890122e-05, 0.0001064207529077, 7.640023782956541e-05, 3.779488232859094e-05, 1.012514875939948e-05, 1.591426591038884e-05, 5.3819284330574e-05, 8.78464791536948e-05, 0.0001055966771262, 0.0001387693517549, 0.0001381459254511, 0.0001215174522178, 9.78984038302836e-05, 5.23495967737432e-05, 2.586587550993513e-05, 3.900227597206822e-05, 5.09217263760768e-05, 7.66885582646136e-05, 8.08052806023623e-05, 5.7963498612391705e-05, 8.75330206830688e-05, 7.350373054426201e-05, 5.85424365997286e-05, 5.9792668703451295e-05, 5.981642231649839e-05, 4.82055938340402e-05, 5.75598453862304e-05, 4.51476409624476e-05, 2.34164474568708e-05, 1.646418266333478e-06, 2.995213848816128e-05, 8.130442970641889e-05, 0.0001269092535037, 0.0001625971387216, 0.0001452324719882, 0.0001004306499235, 4.249542321364181e-05, 5.466430464842401e-05, 7.86667507382151e-05, 0.0001229060060501, 0.0001321390984315, 0.0001208492696491, 7.23144492331932e-05, 4.48051363927802e-05, 1.125269092033121e-05, 1.1828334464995433e-05, 2.70437172257232e-06, 3.5494689098861004e-05, 6.96270986134296e-05, 0.0001018802406838, 0.0001027221821372, 9.59836192170324e-05, 8.04251760880359e-05, 0.000108133100646, 0.0001117119723127, 0.0001339527439017, 0.000110886462626, 8.91301396803711e-05, 7.863694971985159e-05, 8.12607358994468e-05, 7.03480202752726e-05, 8.14842367631993e-05, 7.06971902265833e-05, 1.215015969383741e-05, 4.4019783638093e-06, 2.9817039839338008e-05, 4.18931594179238e-05, 6.0855526354499495e-05, 0.0001055189411007, 7.56029627230126e-05, 7.25643608663519e-05, 9.25169777666517e-05, 0.0001238323684149, 0.0001535255110864, 0.0002715318055903, 0.00022732725202, 0.0002037597483384, 0.0001788555444434, 0.0001436138172983, 8.20140756616074e-05, 1.9856209434541007e-05, 1.8197576689420388e-05, 4.70242499106967e-05, 0.0001223624192674, 0.0001632954721394, 0.0001523170084018, 8.65211541302329e-05, 1.112951139760636e-05, 1.209519202287776e-05, 4.889294873662951e-05, 7.29380390830049e-05, 7.936666247840621e-05, 8.150267080625479e-05, 6.87065214600312e-05, 5.19720045155476e-05, 4.82047071024985e-05, 4.01996447465642e-05, 4.74194742936008e-05, 6.761973398763219e-05, 8.4177546792777e-05, 8.0330362635393e-05, 3.35664858470777e-05, 5.059497302134291e-05, 7.18741940571108e-05, 0.0001085982505357, 0.0001243130775126, 7.37356430523138e-05, 9.853029520942611e-06, 4.241614742100773e-06, 1.9206606949421948e-05, 8.66377266373747e-05, 0.0001359680888358, 0.0001446849818671, 0.0001367900000863, 0.0001466169949361, 0.0001545373561749, 0.0001532263119625, 0.0001116346219312, 0.0001123894769772, 0.0001008600326806, 8.77208188083392e-05, 9.667294715489032e-05, 7.05837567492573e-05, 3.997424099486757e-05, 3.299404969750477e-05, 6.48476832212003e-05, 8.87586255830956e-05, 7.73904574270192e-05, 3.31094314274659e-05, 2.5165904517277342e-05, 2.513847397373648e-05, 6.67364620269762e-05, 0.0001108252425591, 0.0001316822670684, 0.0001105432156419, 0.0001370028805788, 0.0001429754572091, 0.0001111201125959, 4.599896401584765e-05, 1.631945863454416e-05, 2.07017612309413e-06, 2.3961874278161345e-05, 4.93773204534788e-05, 7.10322039379397e-05, 6.09893953533088e-05, 5.512195684182699e-05, 4.28247603407272e-05, 2.463572640327436e-05, 4.60547874533362e-05, 8.018453106249199e-05, 0.0001041737270538, 0.000110340314199, 0.000103184233258, 8.34933864839885e-05, 9.7575548495856e-05, 0.0001229946202831, 0.0001245231658041, 9.01665392518692e-05, 6.30924778543457e-05, 6.092744431203369e-05, 8.480196013969581e-05, 0.0001279182226987, 0.0001586901564148, 0.000112898911239, 7.38816866837162e-05, 5.5336463420914e-05, 3.295665618209263e-05, 1.232975329882724e-05, 1.504032127520552e-05, 1.7609678379675212e-05, 3.2727808836916335e-05, 7.67242491340636e-05, 9.877407057953978e-05, 0.0001214259874908, 0.0001284733688384, 0.0001349879595822, 0.0001137055470972, 9.4403941545508e-05, 9.61760121590487e-05, 0.0001163189259168, 0.0001111043531391, 0.0001063369785904, 7.09234020942851e-05, 2.1408933442144427e-05, 8.82169100038028e-06, 2.1602819259066587e-05, 7.58829752963285e-05, 0.0001022467116546, 9.18219145284099e-05, 3.975541762217133e-05, 5.658567328276675e-06, 2.574071401268397e-05, 5.7342656262281504e-05, 7.59648706599503e-05, 9.05250455654132e-05, 7.15260388571285e-05, 6.20144852097439e-05, 9.02585549819838e-05, 9.832479551924847e-05, 9.896489582485792e-05, 7.78759694043017e-05, 7.8546685176708e-05, 9.61123441949586e-05, 0.0001084594659212, 0.000103966756812, 0.0001035893140211, 7.029794234379041e-05, 7.171835316981505e-06, 2.99810322252408e-06, 1.072265775789006e-05, 3.320189812744507e-05, 9.23522165153065e-05, 0.000137090153779, 0.0001186684583797, 9.6745340633468e-05, 4.7043367060897495e-05, 5.6331947321902495e-05, 0.0001048406958065, 0.0001506658791782, 0.0001985863093716, 0.0002100780435466, 0.000120014322804, 0.0001548219281426, 0.0001588436040262, 0.0001454665663063, 0.0001101829344282, 5.32771134791392e-05, 7.64132042291189e-06, 5.88282953149648e-06, 3.9346504298530194e-05, 8.734178924529781e-05, 0.0001090506068716, 0.000125685697246, 0.0001002428429956, 6.66675964825598e-05, 5.246516957638631e-05, 6.77424596813134e-05, 0.0001168404159989, 0.0001818756032203, 0.0001873279145284, 0.0001460431314231, 0.0001025330852714, 7.88130910551013e-05, 9.97314118153405e-05, 0.0001657581580505, 0.0002172577348685, 0.0003192756016789, 0.0005041615012269, 0.0007361481855717, 0.0008671400645697, 0.0008089128751842, 0.0005908869906619, 0.000317379045174, 0.000141865961881, 8.37416929904047e-05, 0.0001075696854702, 0.0001162098851001, 0.0001111298623209, 0.0001216943505822, 0.0001496855052625, 0.0001610174908246, 0.0001706358487705, 0.0001612532084023, 7.24517266627102e-05, 6.2556505960236e-05, 2.4672267105795947e-05, 1.7234659286679572e-05, 3.9708425089292e-06, 3.183656503151268e-05, 9.54556847114369e-05, 0.0001471561170745, 0.0001402158839796, 0.0001506983538606, 0.0001655443484838, 0.0001609565351583, 0.0002009910031899, 0.0002255105451333, 0.0001910859094784, 0.0001545809835952, 0.0001340896565003, 0.0001380751640925, 0.0001674717613887, 0.0001895465935738, 0.0001929872415156, 0.000154618275406, 9.30132234015334e-05, 4.535877402882126e-05, 5.024323170593625e-06, 3.456143351759734e-06, 2.038876728201761e-05, 6.18902920875393e-05, 7.651618256769059e-05, 8.62913276885962e-05, 9.35330142114781e-05, 8.82170082513068e-05, 8.89123460249227e-05, 8.58681318775961e-05, 6.918895957498139e-05, 4.33592272937553e-05, 5.69939882025777e-05, 5.625847438126919e-05, 2.6183689032530142e-05, 5.672722231521217e-06, 1.618852837912372e-05, 1.512722973355107e-05, 5.67341298854697e-05, 8.97868599589669e-05, 9.529301661110352e-05, 9.23427308948801e-05, 6.1531083604305e-05, 4.1465359203341344e-05, 2.55045001390384e-05, 3.4196446636486173e-05, 2.7326142542156032e-05, 5.381029255919541e-05, 4.69819819713104e-05, 4.8736368412231605e-05, 3.434265327605976e-05, 1.4063568035409251e-05, 1.389144754620509e-05, 3.4851635406688496e-05, 3.6767634381922856e-05, 6.20511411505472e-05, 9.64625263780392e-05, 0.0001368172216046, 0.000147398830552, 0.0001228151120302, 3.2741200119435865e-05, 3.616440142113189e-06, 2.27863309723444e-06, 3.386006382982021e-05, 7.83085314227013e-05, 8.1484174792367e-05, 5.39413815309306e-05, 2.433545847279553e-05, 4.438715421813847e-06, 4.303737918276143e-06, 2.081719489672739e-05, 3.721127149950842e-05, 4.82877169950771e-05, 6.30211317006262e-05, 8.15849938145904e-05, 0.0001126352997255, 0.0001199603040509, 0.0001084297324052, 8.20957735676181e-05, 2.89924791960244e-05, 3.81260482626972e-05, 4.527115751127161e-05, 4.91620361152778e-05, 4.9115483031822704e-05, 5.592331520553751e-05, 6.94810860107834e-05, 9.038736660573968e-05, 8.18858166898037e-05, 5.167758802710094e-05, 3.776979863171679e-05, 6.513246906706091e-05, 0.0001070454115093, 0.0001456102547017, 0.0001583892190255, 9.6314122578463e-05, 0.0001190695773493, 0.0001066503115717, 5.43656574295907e-05, 2.7126257527910493e-05, 5.01095716607701e-05, 5.807732184852661e-05, 8.91297255076865e-05, 8.00002559247622e-05, 2.8140797197883924e-05, 5.99370531070824e-06, 4.40948068094211e-05, 7.68548693632498e-05, 0.0001123372006551, 9.8844262435474e-05, 0.0001480208248797, 0.0001319143850101, 0.0001234498214959, 0.0001095374950734, 7.847242428878171e-05, 7.97139194254834e-05, 8.6954962487456e-05, 0.0001027874697676, 0.0001292081858176, 0.0001349533122499, 0.0001171761373218, 0.0001361274869082, 9.83080875081313e-05, 0.0001299828306428, 0.0001192722973421, 5.64103987472011e-05, 7.685085373991217e-06, 1.4312256382390911e-05, 9.74690743937891e-05, 0.0001716915553455, 0.000202426930672, 0.0002062103219178, 0.000154823234592, 0.000105584387934, 5.26602883324373e-05, 8.69711977709281e-05, 6.7157021911125e-05, 7.897624504932989e-05, 0.0001021402392497, 0.0001040313722106, 8.453643748032141e-05, 5.07817192689812e-05, 1.737444478939127e-05, 3.69879431037097e-06, 2.521930336333546e-05, 7.09172020815209e-05, 6.89280459059043e-05, 9.10379227469934e-05, 8.58614893986261e-05, 0.0001038790465044, 0.0001359798634994, 0.0001328365306123, 0.0001024768379322, 4.153273617900818e-05, 1.045747460511995e-05, 7.19854341411105e-06, 5.134004474977789e-05, 5.34059691137387e-05, 0.0001362696090652, 0.0001669560173092, 0.0001615283659561, 0.000120794784149, 7.386758831579291e-05, 4.33767792999827e-05, 5.18439077204733e-05, 5.348102092753111e-05, 6.04393461131667e-05, 4.38086792907451e-05, 6.492334848038569e-05, 6.92645311249888e-05, 6.55523350223608e-05, 6.32055606087349e-05, 6.255514746743109e-05, 7.016876000689579e-05, 8.74836634804426e-05, 6.914715178546021e-05, 4.9446298738072095e-05, 6.033063418712439e-05, 4.5655708709089104e-05, 9.856175063329128e-05, 0.0001070081440164, 7.68042491697262e-05, 2.293126668560484e-05, 2.216789576628337e-06, 4.366245124015036e-06, 5.015438073362122e-05, 9.65115775856334e-05, 7.25618461797791e-05, 0.0001333719900198, 0.0001252781503261, 0.0001089753617864, 8.08152638909496e-05, 6.73088962037826e-05, 4.2696740051767296e-05, 2.214004732702022e-05, 2.009315379929595e-05, 4.37253778557094e-05, 3.79555723334981e-05, 5.84053820516013e-05, 8.621295789798349e-05, 0.0001124982929425, 0.0001405187554006, 0.000188526524359, 0.0001778717242417, 0.0001582459644485, 0.0001286236614577, 8.508426048693e-05, 0.0001279387124515, 0.000150023199222, 0.000124813081007, 8.72232467360501e-05, 3.474382216260392e-05, 7.668949969227676e-06, 1.3561890094225e-05, 8.03626022649323e-05, 8.19837365776948e-05, 0.0001573943959616, 0.0001278184041683, 8.835884943257011e-05, 8.21118017565067e-05, 8.56214453859241e-05, 0.0001215444056342, 0.0001217843059349, 0.0001073989101844, 6.051737382916411e-05, 6.99716764585621e-05, 5.223027215485989e-05, 3.176307481916533e-05, 2.051028053454812e-05, 4.110251636591581e-06, 1.51079121687527e-05, 2.569475658145109e-05, 2.242531367698342e-05, 7.840704834759639e-05, 0.0001025733909258, 0.0001018360498763, 7.2047729763808e-05, 7.60212084152783e-05, 5.89138751680485e-05, 5.75470114819882e-05, 7.66890185554252e-05, 4.99913124306522e-05, 5.74441945930134e-05, 6.71822957136125e-05, 6.711564135502171e-05, 4.05540330188206e-05, 2.224767082273602e-05, 3.517885310206959e-06, 2.2911463849751585e-05, 3.80364303009544e-05, 0.0001079100845999, 0.0001550896289903, 0.000179550921287, 0.0001430003598069, 8.08670526173018e-05, 4.736858194298109e-05, 9.79527374922931e-07, 7.030540977322582e-06, 6.0235576119644e-05, 0.0001013964383807, 8.855115628308429e-05, 6.85361751945777e-05, 2.329984583741611e-05, 1.756604360142874e-06, 7.07338796539606e-06, 4.124827408342311e-05, 5.72155228527711e-05, 6.451282917535359e-05, 5.97697319658494e-05, 6.243713043638431e-05, 6.39466539078133e-05, 5.9179155063436094e-05, 5.1853234028325805e-05, 0.0001183087195762, 0.0001643820854896, 0.0001622286758698, 0.0001558742281074, 0.0001307944382386, 7.51466403836976e-05, 4.59772650443583e-05, 7.63004164084163e-05, 7.24601334797569e-05, 5.911545262039171e-05, 7.411079461540929e-05, 8.67391498228356e-05, 5.542615770968221e-05, 3.86808830140069e-05, 2.14155138893527e-05, 6.017568777270178e-06, 8.40381665866239e-06, 3.313693953894865e-05, 2.96404937077427e-05, 1.844070446218154e-05, 1.598689353966827e-05, 1.670756891060797e-05, 2.494175477928288e-05, 2.522913634344262e-05, 3.62969100615901e-05, 3.654054026230221e-05, 1.6818746731114958e-05, 4.51581389277599e-05, 4.34653721522301e-05, 4.77627683463092e-05, 2.7228490742871603e-05, 2.2204677362099373e-05, 5.585315481807e-06, 1.164068333436472e-05, 3.55895202272472e-05, 2.74791016059373e-05, 3.88522504016752e-05, 5.00770802783156e-05, 3.7421275733463805e-05, 4.072635399453061e-05, 4.9181421653894094e-05, 6.35858079996311e-05, 4.716977676820929e-05, 7.29632662498691e-05, 4.556723997965808e-05, 2.207426897085805e-05, 2.126923594828479e-05, 2.004810880965754e-05, 1.436275009619502e-05, 3.20912531733395e-05, 2.8326599324544527e-05, 2.949810595538903e-05, 3.97934942046968e-05, 1.463377902617324e-05, 4.471717277197912e-06, 3.48185426072213e-05, 0.0001289368379907, 0.0002774741761245, 0.0003918316174343, 0.0004067547602414, 0.0002991188148301, 0.0001202040799919, 7.410678171253579e-05, 4.53911961511796e-05, 4.86291419144489e-05, 6.297754320639339e-05, 0.0001042584847414, 0.0001036677488373, 5.31526880743784e-05, 0.0001019901912691, 0.0001465652405445, 0.0001342329707413, 9.532162517303712e-05, 7.92404950482225e-05, 4.28075806910512e-05, 1.228823474532708e-05, 1.333377621952753e-05, 1.5467854417396758e-05, 8.216290715579899e-06, 8.17559970280501e-06, 1.752401557165405e-05, 5.25740644511161e-05, 4.5420543021614296e-05, 4.197382836247819e-05, 2.967443124618276e-05, 7.0021753234852e-05, 4.3813643390366905e-05, 4.68598064531433e-05, 4.09909814312375e-05, 3.58309557609385e-05, 4.46956117977246e-05, 7.02624908567665e-05, 6.371171791933139e-05, 2.52605891975026e-05, 4.48917473151588e-05, 4.49397543561484e-05, 3.90947689467533e-05, 4.68039759445284e-05, 3.824125476925272e-05, 5.78589995771643e-06, 2.344854719411146e-06, 1.674278558722429e-05, 3.3558876672105747e-06, 2.9992283205543327e-05, 6.64200652749286e-05, 4.64353638295792e-05, 6.31192127284994e-05, 6.120443039645961e-05, 3.178223488125613e-05, 2.046894658588163e-05, 1.507160719102904e-05, 2.451635071885772e-05, 2.69625268047083e-05, 3.56132776858878e-05, 3.66459986175488e-05, 3.70135873662501e-05, 3.26106794810069e-05, 3.5748545614798e-05, 6.189442126755181e-05, 9.21134425418583e-05, 8.472502745628659e-05, 5.8001677393136e-05, 2.26768425583306e-05, 1.164224260440598e-05, 3.927543245350581e-06, 2.494542150490883e-05, 5.13220483078215e-05, 8.569119084198249e-05, 5.9949282691412e-05, 8.89162771871181e-05, 8.91948191604784e-05, 6.33738489820589e-05, 3.626340986889681e-05, 2.1140384274822992e-05, 4.5394771340475805e-05, 3.492957364995756e-05, 2.902775622693261e-05, 3.712732902622635e-05, 4.46726889253923e-05, 2.69735772902614e-05, 4.41880478935339e-05, 3.25111748274578e-05, 2.0387021479230747e-05, 6.856453603603371e-06, 3.68529570789866e-05, 6.795466816112171e-05, 5.45717042510266e-05, 5.81788538826322e-05, 6.15828848503543e-05, 7.48660056145047e-05, 5.48431943133032e-05, 8.86783809398764e-05, 5.9408622866462696e-05, 2.90477066856748e-05, 3.5337170719740696e-05, 2.076796214212204e-05, 5.6668037999472594e-05, 7.829577632748069e-05, 7.42265525412996e-05, 5.3477509607008505e-05, 1.487035174131828e-05, 2.890342077125532e-05, 1.109251553425654e-05, 1.2921214009204849e-05, 5.629938425578351e-05, 8.13616526844436e-05, 4.28323526985835e-05, 5.07939630784397e-05, 5.251783593447909e-05, 1.915906365711527e-05, 5.49475064083848e-06, 3.36641348771318e-06, 5.1675639293659405e-06, 2.58114044527893e-06, 7.296173273555917e-06, 2.404342517720023e-05, 2.1709801382060905e-05, 4.25643248604528e-05, 4.328578174155981e-05, 3.97860974519143e-05, 5.06636237555476e-05, 3.96447654375198e-05, 3.232744496152473e-05, 2.6933805264166815e-05, 3.103266649442302e-05, 4.05586730522095e-05, 2.48744054266569e-05, 7.62053023857211e-05, 8.48408828807647e-05, 6.44512055683566e-05, 5.484879862486571e-05, 5.719894396932861e-05, 2.446844269449329e-05, 3.349966744217145e-05, 5.19772542769699e-05, 9.20628842473957e-05, 0.0001166422009474, 9.08170811722426e-05, 0.0001221971794185, 6.171492848543769e-05, 1.926407462388391e-05, 6.54092349561194e-06, 1.782450905814553e-05, 6.738188376679591e-05, 0.0001088603484313, 0.0001303263304018, 7.76692065294111e-05, 8.054028832177571e-05, 3.449547522817423e-05, 5.60093128781975e-06, 6.654839569981966e-06, 1.807689488709666e-05, 4.07783237486219e-05, 2.308799750412814e-05, 3.08377704553093e-05, 3.71056930523664e-05, 2.59964645654844e-05, 5.4296076137405005e-05, 7.22103598698407e-05, 5.332899310643159e-05, 2.314008779411492e-05, 2.53923362537699e-05, 5.82472895496746e-05, 6.33541352838441e-05, 9.94522006125482e-05, 8.41562875038091e-05, 4.38949632368565e-05, 7.95884979461256e-05, 0.0001740824131202, 0.000297652135608, 0.000371904724526, 0.0002443487080312, 0.0002689259082648, 0.0001584082863973, 7.11752412437596e-05, 1.462230887902887e-05, 1.927563385553451e-05, 1.176957696747003e-05, 1.049323711442918e-05, 3.488312039564358e-05, 3.4527018576480296e-05, 7.76246288953468e-05, 7.57051882372182e-05, 8.45195770548826e-05, 7.236972993671101e-05, 4.40653526486316e-05, 4.47405146548337e-05, 3.456540333588441e-05, 2.2980915463171825e-05, 1.438930317292626e-06, 2.023469821229209e-05, 4.14198773976418e-05, 6.36979750401828e-05, 8.33565237706222e-05, 5.8972462253486e-05, 7.17897454482359e-05, 3.080472915011431e-05, 2.5467623447660293e-05, 1.013898729935505e-05, 2.229194588546764e-05, 4.0316426332919e-05, 4.20350230814441e-05, 2.002031039881894e-05, 1.887440527761014e-05, 3.258459772923755e-05, 1.734320892751671e-05, 2.772797977341158e-05, 2.6779765507360265e-05, 1.636494195035486e-05, 2.5192206220714e-05, 4.71882449031226e-05, 3.542015199872793e-05, 8.085397620518011e-06, 9.257793716784009e-06, 1.407780587736989e-05, 3.397633591689045e-05, 6.02730275187664e-05, 0.0001572721183635, 0.0001887966202583, 0.0001846415899891, 0.0001323121209592, 4.673633126104349e-05, 1.4026138929515408e-05, 9.59639172138519e-06, 4.13172743851874e-05, 4.2802484963963e-05, 0.0001057269635814, 0.000132207435062, 0.0001368591946857, 0.0001282889899699, 8.03327764097009e-05, 0.0001144739996699, 9.829866669105632e-05, 8.932938405161219e-05, 4.67198152492319e-05, 6.14525687466202e-05, 6.0028107037582e-05, 7.10444704590551e-05, 5.56208456498668e-05, 9.58332744897152e-05, 9.72714916343262e-05, 6.91592118917116e-05, 5.61660655429062e-05, 3.12938909808563e-05, 4.5652748087169e-05, 4.4851835880916e-05, 4.9515855834643696e-05, 2.7259028198817e-05, 9.072852049348388e-06, 3.7839637362798e-06, 1.9991023737121188e-05, 2.0502790347991295e-05, 3.64586639956809e-05, 4.1583129635573e-05, 4.07118578969659e-05, 2.3122730076894203e-05, 3.0090894183401163e-05, 4.26387433415703e-05, 2.5764753330409625e-05, 1.984101865568306e-05, 2.45543835270431e-05, 2.8661998547770365e-05, 2.7035061009794088e-05, 4.1890794039731895e-05, 3.57996561541794e-05, 3.3043390827087275e-05, 5.654339692771699e-05, 6.9407127467877e-05, 3.5115282149857e-05, 3.064121055961526e-05, 3.36004681791929e-05, 9.85952697183428e-06, 8.81495818384663e-07, 2.360057737258886e-05, 5.3172204474614505e-05, 6.64299808259155e-05, 4.85684654203393e-05, 6.98272206992068e-05, 4.67511645866503e-05, 3.635887006245197e-05, 1.4569765619814387e-05, 2.554328202649226e-05, 6.8214869156113e-05, 8.35282183111863e-05, 4.15852044210695e-05, 6.42934642742836e-05, 4.772786632743445e-05, 2.3999798249624053e-05, 2.5429475287825e-05, 5.12715899779073e-05, 2.63543795074488e-05, 6.431207491166853e-06, 3.42838527588482e-06, 1.4730015480855087e-05, 3.468586054844792e-05, 4.09701157058317e-05, 2.97395867922329e-05, 3.133886344328266e-05, 2.482428395362185e-05, 7.33207501538266e-06, 1.365643678708708e-05, 4.49294884237086e-05, 3.94784854427946e-05, 4.22597811066502e-05, 1.879912680193278e-05, 2.513012141963473e-05, 4.54691411903762e-06, 1.188088031739024e-05, 2.139735433473e-05, 3.58340924382234e-05, 6.22399368772304e-05, 8.09042981047113e-05, 4.2248417988499504e-05, 4.74800098058024e-05, 1.395335032422218e-05, 2.202954779269528e-05, 3.43247210720259e-05, 8.170761819850691e-05, 9.67210616156498e-05, 7.89348596706979e-05, 5.57502372190696e-05, 0.0001092784762695, 0.0001616803065928, 0.0001810978739597, 0.0001098846671668, 0.0001368633472482, 9.009136737735091e-05, 5.65562398250856e-05, 4.2135227190559e-05, 7.903100315231101e-05, 0.0001013227328638, 9.08853260657793e-05, 0.0001811673462294, 0.0002015710257628, 0.0001838253424359, 9.77966122170564e-05, 9.889637694401751e-05, 7.474664363805181e-05, 7.48129265089926e-05, 5.48651232102046e-05, 8.882517942093181e-05, 0.0001061969664678, 8.812307104676072e-05, 2.3685594407849623e-05, 5.277815641321914e-06, 1.75460330541939e-06, 2.9267474259960005e-06, 2.647433499209179e-05, 0.0001052072706356, 0.0001642248525019, 0.0001166050749704, 0.0001564829816343, 0.0001215788220866, 6.455602380762599e-05, 3.30049615958423e-05, 5.5517951417143695e-05, 7.8416985731211e-05, 0.0001063588138362, 6.458138348038099e-05, 5.5190774664127406e-05, 4.5182315161086006e-05, 5.38922292779632e-05, 4.84096717007362e-05, 7.94843518686353e-05, 9.44543154040204e-05, 5.28441991889018e-05, 4.39720531827071e-05, 1.803726336289137e-05, 5.81921451403423e-06, 3.57029524332019e-06, 7.23918977296692e-06, 2.441915880141657e-05, 4.774144178830351e-05, 4.43476318092716e-05, 7.41683103978901e-05, 7.04528383438825e-05, 3.97647584285003e-05, 6.15961077579694e-05, 7.14573705738056e-05, 7.78680952913348e-05, 6.590152086517459e-05, 0.0001253552328501, 0.0001160020368832, 5.94080444047699e-05, 7.880127175251e-05, 5.951212678147819e-05, 1.246272746185797e-05, 8.473828436536996e-06, 4.859706410197801e-05, 6.8534549863772e-05, 7.927014484742289e-05, 4.50294755017251e-05, 3.970219871768339e-05, 4.132439515869068e-05, 5.24389505238824e-05, 0.0001168992611227, 0.0001455977541495, 0.0001325498832133, 5.578337123220041e-05, 4.6160103170421606e-05, 3.5643284692605804e-05, 3.07706560686558e-05, 3.8808311832934696e-05, 2.498874660640038e-05, 6.52163025176109e-06, 1.088659004422627e-06, 9.869950668366363e-06, 3.444343905940376e-05, 3.4552680813435904e-05, 4.55655638937184e-05, 1.935069554990377e-05, 1.330332451496825e-05, 1.069687420775697e-05, 3.7543256490997e-05, 7.88831017166922e-05, 7.599156140094651e-05, 0.0001218528262938, 0.0001064063109656, 7.27545291924242e-05, 4.36553038773706e-05, 5.6509588522931205e-05, 5.1031866879114905e-05, 4.63829393350907e-05, 6.3287200648778e-05, 2.84008676147038e-05, 6.324742120111674e-06, 2.177847969810774e-05, 4.83550633396725e-05, 7.384638619344449e-05, 5.99514765240828e-05, 8.743722375940309e-05, 6.16360484350767e-05, 3.0417132509466707e-05, 1.910297214827628e-05, 2.599585119915169e-05, 4.53558801966093e-05, 2.92024803304927e-05, 6.53720952249915e-05, 5.4139281254383096e-05, 2.288380933014729e-05, 1.9365959464121727e-05, 3.8240773184613095e-05, 7.080146190091551e-05, 5.85991805144304e-05, 9.7401674259074e-05, 4.6784886416918536e-05, 1.15095112364467e-06, 8.54367441285941e-06, 5.6837233664144e-05, 0.0001255203791917, 0.0001033067665726, 0.0001360703397226, 6.925552686763111e-05, 1.825730542100328e-05, 1.6325032898329792e-05, 3.754476470198703e-05, 3.75312193060443e-05, 5.928699789978929e-05, 3.9809844291959104e-05, 1.240093742239993e-05, 2.008099656590603e-05, 1.731184355004997e-05, 9.04468428012626e-06, 2.39987517909983e-05, 5.27084335441257e-05, 5.63334199429543e-05, 3.5430841843825e-05, 5.00342511705904e-05, 2.204672278243866e-05, 2.665395872383896e-06, 1.659834153449275e-05, 2.187368320094554e-05, 1.5321529121586753e-05, 2.092713344811574e-05, 3.715332604630441e-05, 8.7907850035496e-05, 9.76481780604736e-05, 0.0001740611553422, 0.0001501871266367, 0.0001076146318815, 3.7437755744829504e-05, 1.3628952675485888e-05, 9.502153183570722e-06, 1.376688773891586e-05, 3.016944077101779e-05, 6.81238774280299e-05, 6.06097337572255e-05, 8.39291455030849e-05, 7.02516558501645e-05, 2.68448862597908e-05, 2.034565126451431e-05, 2.189319801368671e-05, 3.75687878771986e-05, 2.59807281907019e-05, 3.3921705826414706e-05, 2.639398272119911e-05, 2.3875667342961694e-05, 5.64876549846532e-05, 5.248499360452379e-05, 2.99577797805228e-05, 2.206099787668273e-05, 1.362233146576342e-05, 1.150729977774479e-05, 2.510868077570681e-05, 3.9955703811726096e-05, 3.021739567761431e-05, 2.095886790298477e-05, 3.152895676269109e-05, 4.55376051834392e-05, 3.33727403050036e-05, 3.321959722649015e-05, 2.742529843140501e-05, 1.712029385793354e-05, 4.67691188423188e-05, 8.03066695671039e-05, 6.21867481890031e-05, 0.0001130219097883, 0.000126693127888, 7.81093906159337e-05, 0.0001087040779563, 8.840833577335351e-05, 3.89853287902067e-05, 1.3561659501471928e-05, 2.421019462978941e-05, 4.456984503266491e-05, 4.52126849118311e-05, 6.47119332951267e-05, 5.318649921898229e-05, 2.59698443742219e-05, 5.476174321076406e-06, 3.2375529542969086e-05, 3.77117898837902e-05, 6.99918957923635e-05, 8.03415019034043e-05, 6.76569103061287e-05, 0.0001049451727191, 6.41210588814973e-05, 4.28851618101022e-05, 6.62703933356591e-05, 6.70664057143763e-05, 5.75557300101455e-05, 0.0001053149140282, 9.88877264128633e-05, 6.581129143840749e-05, 0.0001062193418984, 7.58938350082333e-05, 2.23072275716959e-05, 8.9674927450057e-06, 4.43960192140573e-06, 5.063516668079816e-06, 6.62345788178529e-05, 0.0001223156095433, 8.59945765061478e-05, 9.06275345931536e-05, 8.57119239395657e-05, 7.36036513740148e-05, 3.08452061455789e-05, 4.73914433401637e-05, 4.0963107976385503e-05, 2.0584387634350167e-05, 3.49529778498968e-05, 5.697208841445911e-05, 3.24385204582655e-05, 3.67638840238772e-05, 5.3264027324031e-05, 3.03084552114148e-05, 4.779158837664261e-05, 6.31242235865477e-05, 4.09578179649188e-05, 5.3783148833051904e-05, 6.14204722636802e-05, 4.5754412783067394e-05, 5.99804022714376e-05, 6.128378944977209e-05, 3.00589754577872e-05, 5.07945992214523e-05, 5.1799617803945206e-05, 2.177658680187546e-05, 1.842562176221996e-05, 4.187302735357768e-05, 3.01553137637532e-05, 4.27741486294917e-05, 5.929525132065271e-05, 4.09056151235767e-05, 5.40201532942647e-05, 2.740487920329566e-05, 1.21868656302638e-05, 1.476932105421813e-05, 2.419800553782504e-05, 3.24092684237727e-05, 7.56155636294882e-05, 0.0001183727386329, 7.92811743798307e-05, 8.01464041339317e-05, 5.84493773856811e-05, 2.90302062433746e-05, 5.24399430125299e-05, 7.94225173547022e-05, 5.5255064766641904e-05, 7.785535881158371e-05, 4.03340439443152e-05, 1.085121307905127e-05, 4.291663670857399e-06, 2.434308809927206e-05, 8.05089794339582e-05, 0.0001131675940755, 8.929883282787589e-05, 0.0001243956977297, 0.0001045774629033, 4.491732206799881e-05, 5.09661452464285e-05, 1.702020582818141e-05, 6.33299500075905e-06, 1.3830696432345202e-05, 4.2972501975373e-05, 5.39822808087953e-05, 0.0001098192485807, 0.0001320092032949, 8.161993028420189e-05, 9.780423214269778e-05, 6.15373220654181e-05, 3.4232079918299e-05, 6.04691183464406e-05, 9.490090541494768e-05, 5.70013082858323e-05, 9.97975644972871e-05, 0.000103976298713, 7.441153747110181e-05, 0.000117921762658, 0.0001493161522866, 0.0001164724276422, 0.0001801699770707, 0.0002001815811746, 0.0001297615581756, 0.0001649737884814, 7.56426136428213e-05, 6.54925802687965e-05, 9.42104427978078e-06, 7.071199452148501e-06, 4.9879204965469295e-05, 5.85690975278888e-05, 5.2134213404518e-05, 8.85875094778911e-05, 7.729856074366971e-05, 2.92809718335158e-05, 2.54824532810226e-05, 1.729747104231073e-05, 1.84069003687402e-06, 5.89802212192342e-05, 0.0001428540313992, 0.0001184003400015, 0.0001603987258244, 9.97868487081345e-05, 0.0001219784244901, 8.454027404399301e-05, 6.71382340800727e-05, 0.0001258895806885, 0.0001141568955465, 6.800121567514361e-05, 0.0001162583216844, 0.0001078537678546, 4.872302760100389e-05, 6.502264897020199e-05, 2.667003073032657e-05, 3.69145459442934e-06, 2.972422693981768e-05, 4.56615642948848e-05, 0.0001159270016467, 0.0001170227012804, 7.638001712856179e-05, 0.0001199603824372, 0.0001217517076381, 9.05222095542916e-05, 0.0001136429049034, 7.42609988963091e-05, 2.55148390945136e-05, 1.005222473105748e-05, 1.600097539445269e-05, 3.26901262533316e-05, 9.40188111963578e-05, 6.31459261539082e-05, 8.1792931074315e-05, 5.8155793093122806e-05, 2.2617473689995276e-05, 1.3068507540792232e-05, 3.302989422932195e-05, 2.94226687723473e-05, 3.020847994996324e-05, 3.4020296977363e-05, 3.16050998630749e-05, 7.55060940040578e-05, 6.233492022193529e-05, 9.13953596091212e-05, 7.508237594672611e-05, 2.96030958526831e-05, 3.186880354456265e-05, 4.59755903354561e-05, 4.19197356840255e-05, 4.3621330774198594e-05, 2.047303598569662e-05, 9.38769141425674e-06, 1.5233961039968053e-05, 1.8774905103691597e-05, 2.339456877299091e-05, 1.221734797001517e-05, 2.33632579046397e-06, 1.53124659420393e-05, 3.348015175096819e-05, 3.4884477074643496e-05, 7.95818338452234e-05, 5.9249565671717206e-05, 8.56590127570929e-05, 7.13054202356707e-05, 4.24175086571117e-05, 6.461532552932899e-05, 7.08911520964752e-05, 4.67810235699426e-05, 6.35704763827927e-05, 6.28713176857022e-05, 3.09543735361111e-05, 6.451176163699209e-05, 5.050974736544759e-05, 9.1191758922463e-05, 7.83464833475262e-05, 4.27937090471591e-05, 8.49733409639522e-05, 6.46820508490759e-05, 3.5782655665118e-05, 4.4334987918078784e-05, 1.407254197108556e-05, 3.538258422976291e-06, 1.071751371316928e-05, 3.34797445710974e-05, 4.52507501278611e-05, 6.39713369015762e-05, 6.33562602417771e-05, 9.00293075786977e-05, 5.910384225421e-05, 8.57530515615426e-05, 8.152843190691241e-05, 4.23589424630661e-05, 5.84759123723063e-05, 4.9926292276397e-05, 9.99473781418176e-06, 3.3094276011437547e-06, 4.363416727776824e-06, 4.318855294195675e-06, 2.335838483863912e-05, 2.6258760483603003e-05, 5.06658943795141e-05, 3.01198032109032e-05, 3.3031931107758e-05, 4.92811129111505e-05, 2.70822544028844e-05, 4.24763577669591e-05, 4.474253051765909e-05, 3.07662889355539e-05, 6.38072321957161e-05, 3.4496848778736805e-05, 4.92473362444763e-05, 2.8916539708126537e-05, 3.42172330845463e-05, 6.96748844240357e-05, 3.4714815834917696e-05, 6.22077440899342e-05, 7.573174068432141e-05, 5.07540693359574e-05, 4.7378707125104896e-05, 5.388491436188141e-05, 4.90172063733572e-05, 3.748045133911718e-05, 1.075741025736026e-05, 1.469218781908642e-05, 2.081849159529966e-05, 2.0783540941998105e-05, 2.9293394793456335e-05, 2.7328274911609905e-05, 3.432010611030139e-05, 9.80019366882039e-06, 1.99767379681871e-06, 1.309733985670339e-06, 1.539029174717849e-05, 2.60702939639201e-05, 6.04773840368953e-05, 5.71408537822976e-05, 9.47638090394665e-05, 8.07832825232852e-05, 3.1251138675219e-05, 2.12350287982304e-05, 1.244902075115405e-05, 6.06155357448358e-05, 0.0001071523660983, 8.558593877377771e-05, 0.0001166646692387, 5.23420540950784e-05, 3.675340160108853e-05, 2.125379734807543e-05, 2.7530637004238e-05, 4.07845012747023e-05, 6.61320219594584e-05, 7.107651509841772e-05, 0.0001212291949075, 8.82093349071589e-05, 0.0001414592287401, 0.0001405009657092, 6.84014687588476e-05, 6.82177845523592e-05, 3.06091447003788e-05, 1.7219087667365618e-05, 1.250407694358258e-06, 5.507728857214679e-06, 3.6985791163406536e-05, 3.43332535653268e-05, 7.51027540377072e-05, 8.52149329727839e-05, 5.2147221377217e-05, 7.41360915610485e-05, 6.802963354533671e-05, 0.0001398560858786, 0.0001972874735263, 0.0001665963020072, 0.0002914339708698, 0.0001914116459095, 0.0002655416688597, 0.0002221908747256, 0.000121955917669, 0.0001521324031566, 9.32957338946663e-05, 0.0001443800923037, 0.000139470157076, 0.0001006942774562, 0.0001709613648078, 0.0001284264358773, 0.0002005446432088, 0.000183893847328, 0.0001055847471357, 0.0001023179248872, 2.856813661271758e-05, 4.90004190122881e-06, 2.023227610307462e-05, 1.752234968924507e-05, 4.7524185037440896e-05, 5.15903436457281e-05, 6.670591164499969e-05, 3.32308259823408e-05, 2.350240776052186e-05, 6.16325047527748e-05, 5.21860603836909e-05, 9.494860065990928e-05, 7.08307821396304e-05, 9.201075062073692e-05, 7.16321357087245e-05, 5.16947748205127e-05, 9.15988278967358e-05, 6.723256843092551e-05, 0.0001224145673857, 0.0001394559129511, 9.84830452749937e-05, 0.0001321759835348, 7.03198001386039e-05, 8.57489020362815e-05, 5.84241295896144e-05, 3.99673165868403e-05, 5.43958899186223e-05, 3.98577415981651e-05, 4.926244502521369e-05, 3.98840066701566e-05, 1.793740043088472e-05, 2.5289770026883912e-05, 3.47342228883282e-05, 6.91383021295332e-05, 4.6948128034774e-05, 7.28486512491053e-05, 6.523800570041951e-05, 2.88558163348695e-05, 3.0788718658386534e-05, 2.63934510990066e-05, 2.443537075639299e-05, 5.49605800067396e-06, 1.158032640758639e-05, 2.853664078342556e-05, 2.65186561686e-05, 3.86677207085091e-05, 6.65955004969243e-05, 4.10782784775365e-05, 7.054741740495881e-05, 5.66959421698052e-05, 8.9461700921864e-05, 4.58449045657552e-05, 4.34161810157945e-05, 3.534810299518042e-05, 4.847566116960945e-06, 1.542948020275343e-05, 1.834507783911598e-05, 2.361110215557314e-05, 5.924979974626003e-06, 1.7100071750290038e-05, 3.93082218493729e-05, 3.4182569444778406e-05, 8.67029167355968e-05, 8.13906237190654e-05, 9.96890448455051e-05, 7.48895965174114e-05, 3.3081358430071394e-05, 5.924563606174909e-05, 4.44522237632823e-05, 9.80358369310702e-05, 7.856140546735421e-05, 9.59234707759144e-05, 8.57429195746753e-05, 5.3708714056828594e-05, 6.418683388542299e-05, 5.39658339646144e-05, 7.42908738146864e-05, 8.08386004413761e-05, 3.5736179755962195e-05, 3.53203110449023e-05, 2.2559204787159305e-05, 8.1338216690145e-06, 8.4591480612327e-06, 4.65279661795255e-05, 9.33191687703848e-05, 7.491552150668649e-05, 0.0001103200201294, 7.689585238535951e-05, 9.95702309577295e-05, 4.3870292983826e-05, 6.26184666115641e-05, 7.06718221300852e-05, 5.37630209821248e-05, 9.17399623866166e-05, 8.67770106097681e-05, 0.0001767892047397, 0.00011359727463, 0.0001531604806871, 0.0001080503614889, 4.656927205948779e-05, 2.546924475384681e-05, 4.555439698629477e-06, 1.047893130127358e-05, 4.58407096969238e-06, 2.696902017887732e-05, 4.90860408514257e-05, 4.3534043635819696e-05, 5.82945465619874e-05, 3.82811214505014e-05, 4.55524983079946e-05, 3.32071012061474e-05, 3.77997723166932e-05, 2.453429047611683e-05, 8.43277320820554e-06, 5.02885037497643e-06, 1.932361901069597e-05, 4.08618715050609e-05, 5.2273802337067206e-05, 0.0001022306923836, 0.0001022947409982, 6.22949678754603e-05, 7.498419136924521e-05, 5.63009261563971e-05, 5.14918124271792e-05, 2.4474476766056603e-05, 4.842520416874831e-05, 1.0882116208927987e-05, 2.142263265644481e-05, 7.0652079792547095e-06, 1.912765061421378e-05, 1.44449227041275e-05, 7.553970017368919e-06, 6.27012251684264e-05, 4.72429460302595e-05, 7.538683963541739e-05, 7.515219603941791e-05, 5.30314146247948e-05, 5.9923740148514704e-05, 2.63165791547408e-05, 2.4282055239655775e-05, 3.958843721983101e-06, 3.84952993237933e-06, 8.00848081989779e-06, 2.069449579389113e-05, 4.1937573246101305e-05, 3.7676210230996e-05, 5.6978973895437706e-05, 3.02008475261426e-05, 4.74909775094663e-05, 4.2748001983661e-05, 8.852065792119319e-05, 0.0001116110190087, 8.64447351698691e-05, 0.0001175913287818, 6.809895921341609e-05, 7.98120294725786e-05, 2.7673893341562696e-05, 3.70064886985914e-05, 3.5335000036978395e-05, 7.057156812954979e-05, 9.449327589826728e-05, 6.295756325455629e-05, 0.0001101143291688, 7.23049963976596e-05, 0.0001092824267898, 9.050923826145952e-05, 0.0001616808120934, 0.0001258932415871, 0.0001893978157726, 0.0001777293701688, 0.0001125493711488, 0.0001263410625392, 5.75769107416141e-05, 4.4025035202126505e-05, 1.1766279915668409e-05, 3.229906066389675e-05, 2.46132089988761e-05, 6.4424542345305e-05, 6.87828090491593e-05, 0.0001325622599576, 0.0001466079028788, 9.117263118595428e-05, 0.0001330137716098, 6.52011587372005e-05, 6.38525814547574e-05, 3.47702468809065e-05, 3.71146083477482e-05, 2.4576777737910698e-05, 4.28828298898776e-05, 5.12791508050841e-05, 2.61620375845457e-05, 1.205658180538783e-05, 4.25396369104519e-06, 2.015133674842799e-06, 1.0626223813040529e-05, 5.99837125234171e-05, 5.43414922415391e-05, 9.44240990660078e-05, 5.6893637493311e-05, 6.23345823437063e-05, 5.13330418519504e-05, 2.07890729874269e-05, 1.1922385815815e-05, 1.74343890271483e-06, 5.80023279603372e-06, 1.381699183219227e-05, 2.795214922125965e-05, 3.5559733529679505e-05, 6.90882573924274e-05, 4.96453340006209e-05, 0.0001037906358367, 0.0001144164160038, 7.45112084123829e-05, 8.998896414300169e-05, 2.60437571666846e-05, 1.784913372477759e-05, 1.87770467216672e-06, 4.210834450084917e-05, 5.42325359051606e-05, 0.0001154490313615, 8.41722356875384e-05, 9.39107897074205e-05, 5.6178046135135496e-05, 2.74387760899695e-05, 4.83550823661853e-05, 5.12392316028866e-05, 0.0001008329138312, 7.191525055932061e-05, 8.54987583974766e-05, 4.38245539211004e-05, 4.49261331235272e-05, 1.7691538200080508e-05, 2.2591974260803977e-05, 6.80154492838371e-06, 7.1073032445200994e-06, 1.3145026967272516e-05, 2.0987666547692465e-05, 6.72480628049551e-05, 5.75838222200972e-05, 9.35653686785748e-05, 4.48157799793116e-05, 3.88538977216119e-05, 5.537530254694696e-06, 1.775243789219033e-05, 1.089975635488339e-05, 2.1411666453982444e-05, 2.16842470886854e-05, 3.35427950540753e-05, 1.48954425316451e-05, 2.377713152510808e-05, 2.142736782488789e-05, 2.36871199314235e-05, 3.84576203333034e-05, 4.65524955264641e-05, 9.03668161760541e-05, 5.65660620198453e-05, 6.39289861074243e-05, 2.51912013460295e-05, 7.422364222606225e-06, 7.05766549134339e-06, 3.1256930353974e-05, 4.07032333961736e-05, 6.26950291176615e-05, 4.23616353530475e-05, 7.16440998854101e-05, 5.685745489218511e-05, 2.30228099168017e-05, 2.340198848788811e-05, 2.7822383620906654e-06, 6.67184413037389e-07, 1.3281882621342207e-05, 7.81875337189961e-05, 8.16770897546233e-05, 0.0001183422271818, 6.55823613602369e-05, 6.87106324679424e-05, 2.93176448983112e-05, 4.60442586896797e-05, 3.8023177250636205e-05, 5.375867873172449e-05, 4.45775187389991e-05, 6.984443721481309e-05, 7.362764869337161e-05, 6.30487828369914e-05, 9.40068117975174e-05, 6.87354324424611e-05, 8.0079903089685e-05, 4.6566191747681895e-05, 5.85567539238906e-05, 3.09957555485993e-05, 2.9545591267401897e-05, 7.81311610844612e-06, 1.6158337135491758e-05, 2.61983835494416e-05, 4.3566894021012e-05, 2.2832364477610803e-05, 2.963454670782635e-05, 2.18898775757142e-05, 2.292202852724249e-05, 1.442664416595543e-05, 6.0180875404466496e-05, 4.68801580187729e-05, 6.16669481222766e-05, 4.41713049859653e-05, 2.025616002133336e-05, 9.614922655344016e-06, 8.391144905710491e-07, 4.509693644774678e-05, 5.17863708562652e-05, 7.1227326150639e-05, 4.31407986704686e-05, 5.8848128035687104e-05, 2.0577836952390297e-05, 6.89765139751091e-06, 3.74819038660494e-06, 2.711599591824887e-05, 3.1970900381424495e-05, 4.80102833559092e-05, 4.22885152890763e-05, 8.022633071290269e-05, 4.98625541251406e-05, 7.34356746640468e-05, 2.73011812712649e-05, 1.703484125771933e-05, 1.292907197770062e-05, 5.140798979352391e-05, 6.206068615204879e-05, 0.0001288027893582, 0.0001021851006843, 0.0001330564036238, 4.9472803542432994e-05, 5.8727464256255206e-05, 6.12474810575139e-05, 4.36544722087789e-05, 6.8050893035409e-05, 5.24455304179218e-05, 4.718336289869028e-05, 5.69832639930898e-06, 1.0620155686693951e-05, 1.190013756691144e-05, 2.775319620736257e-05, 4.7945480665932094e-05, 0.0001097091736535, 9.947912062755112e-05, 0.000159772204967, 0.0001225623602463, 0.0001804427528955, 9.34120519129968e-05, 0.0001082759536656, 3.14256252646586e-05, 2.153846376754028e-05, 2.291896781825487e-06, 2.407324623568167e-05, 2.80558237694141e-05, 5.831456589720889e-05, 4.32527158571731e-05, 4.990427088399791e-05, 3.21583407681752e-05, 4.25072715071921e-05, 2.50356276677601e-05, 3.310646665626725e-05, 1.312726290164241e-05, 1.147636144091408e-05, 1.84965136899855e-06, 1.6152589901240188e-05, 2.108427314870608e-05, 4.97770659390667e-05, 4.706121387903271e-05, 6.66742706767961e-05, 3.49227106822644e-05, 3.615984624865e-05, 2.28763675065783e-05, 4.412855124015551e-05, 3.03017557038755e-05, 4.6873848956462e-05, 2.31626918636087e-05, 3.145346645611799e-05, 8.9003359020658e-06, 2.657112165102291e-05, 4.65992814217866e-05, 8.794140271454519e-05, 5.5600691011361605e-05, 7.620316007732401e-05, 4.69123849250182e-05, 5.920374680636849e-05, 2.36172026840162e-05, 3.93488235295937e-05, 2.43656948326035e-05, 1.0043984467250294e-05, 8.3339923803914e-06, 4.825839075534698e-05, 5.4914538430753e-05, 8.58807638058855e-05, 4.57315518073099e-05, 5.925478140416339e-05, 3.4360688657979305e-05, 1.939464857138529e-05, 1.606326932728726e-05, 5.4135964451124496e-05, 1.321797726928358e-05, 1.0302766343363653e-05, 2.41078415534194e-06, 6.034910030290438e-06, 1.112586578018636e-05, 3.226053556717448e-05, 5.66794610089056e-05, 0.0001040566898246, 4.92063435032982e-05, 6.903198259486769e-05, 1.759020882934912e-05, 3.432289573189664e-06, 1.807504398463749e-05, 7.30965020172186e-05, 7.65263643089514e-05, 0.000128954978171, 9.4528811767065e-05, 0.0001197629019288, 4.16310257195467e-05, 2.793405272849914e-05, 1.583089775209486e-05, 1.5705118602790278e-05, 1.180357763595932e-05, 4.8268116797939504e-05, 4.70435150090979e-05, 5.11042608076642e-05, 2.19422024449488e-05, 4.68394600910609e-05, 3.99677722857665e-05, 5.1962981968032896e-05, 3.4414520264534903e-05, 4.07208437855822e-05, 2.2964262799374905e-05, 3.6351749593554e-05, 3.35099375273685e-05, 9.65642955610075e-05, 8.11536157235641e-05, 0.0001073541737593, 5.41894531861688e-05, 5.4865864538071e-05, 1.921331469350319e-05, 7.642514262558569e-06, 2.488393484832561e-06, 1.2206066095181169e-05, 6.67893538406627e-06, 4.446122353370656e-06, 1.840700315349e-06, 2.359231495944551e-05, 3.58757196128259e-05, 8.7497808457737e-05, 7.98609207704685e-05, 0.0001276598400786, 9.28715738581206e-05, 0.0001262274206677, 9.18582894753217e-05, 0.0001477139869783, 0.0001101027150314, 0.000106821560348, 0.0001234065937948, 6.21708515319324e-05, 6.777676316785039e-05, 2.1294653099572304e-05, 1.829115300611663e-05, 2.6206354660264e-06, 2.446656573838257e-05, 1.872194622464928e-05, 2.430299666388924e-05, 4.35578772512581e-05, 7.977511388787861e-05, 6.462263086591489e-05, 9.07298138094071e-05, 5.71325174097938e-05, 7.7995581453855e-05, 3.82841064883802e-05, 6.27482158144949e-05, 5.494711327785311e-05, 8.726832650624231e-05, 6.733159405436639e-05, 9.56658510713163e-05, 5.6426772307903805e-05, 6.77045485946662e-05, 3.85713032183517e-05, 5.23860908503703e-05, 3.0105730191374e-05, 4.15538916623301e-05, 2.44722471011335e-05, 2.3364546055702295e-05, 2.37884111900853e-05, 1.727137852250822e-05, 1.866959658449011e-05, 4.55535146513583e-06, 6.944862523831145e-06, 1.139370288948521e-05, 3.923539165852737e-05, 3.6535722105957e-05, 5.563511600809909e-05, 4.48160924999858e-05, 5.2176383135573394e-05, 2.03674208804922e-05, 4.08478267205251e-05, 2.98068821215237e-05, 2.863462184054535e-05, 9.54887616089836e-06, 1.1497048925479657e-05, 2.86255359090554e-05, 5.240288227475111e-05, 5.0691885878340106e-05, 5.43725947273673e-05, 3.871888893072525e-05, 1.36490283539203e-06, 1.1065300738797636e-05, 2.72157140219807e-05, 4.35282721762334e-05, 3.12124402719417e-05, 6.7339777623486e-05, 3.93228013747528e-05, 4.6570393968501095e-05, 4.60273594208287e-05, 9.39294198368879e-05, 4.29632868419444e-05, 4.69274137581146e-05, 3.14977363625446e-05, 4.87073916779243e-05, 3.6219800524439895e-05, 7.157009928745428e-05, 5.7619705197015297e-05, 4.3987118104178805e-05, 4.868957065984101e-05, 1.6814076377743267e-05, 3.2216678341102303e-06, 3.405333972638394e-06, 1.323054670576443e-05, 2.61795810023769e-05, 4.67953422348468e-05, 2.64133441437707e-05, 3.319301303911537e-05, 1.3129152277253613e-05, 2.182957835168848e-05, 2.13802919401974e-05, 3.0190703154923563e-05, 1.349381756052644e-05, 6.924579613980621e-06, 8.133962194059651e-06, 8.36851291753751e-06, 2.488490292685101e-05, 2.39450976660546e-05, 4.427541819112511e-05, 2.83998557971939e-05, 2.384819170540325e-05, 2.9497895696199e-05, 4.51977948915386e-05, 4.09569704998871e-05, 5.667963704495591e-05, 4.48918776910786e-05, 6.93862513860421e-05, 4.80748647827898e-05, 4.9823065545723296e-05, 7.518364068552299e-05, 4.81970224780017e-05, 7.55890288722552e-05, 3.4153986578619794e-05, 2.8409270375528568e-05, 9.31123569965336e-06, 1.43820620408831e-05, 1.556916630798779e-05, 3.499062905830348e-05, 3.0082366762250295e-05, 3.47048841148627e-05, 2.0232561402613632e-05, 2.21002650788331e-05, 2.705403204674108e-05, 1.973491660701108e-05, 4.20271418518434e-05, 3.1321769741032e-05, 4.86211931215354e-05, 3.97693115630933e-05, 8.734032472169979e-05, 5.89401331945478e-05, 6.40496594227426e-05, 3.4251323150442204e-05, 2.89805884558411e-05, 3.86221145805522e-05, 2.55091989282241e-05, 3.5742861633173296e-05, 1.505991481083557e-05, 5.35789814820238e-06, 1.9997978682243e-07, 2.1751379935989268e-05, 3.33014299192064e-05, 6.46325220224549e-05, 5.547514432311151e-05, 9.882700272619062e-05, 4.91355629645735e-05, 2.63720965780742e-05, 7.68066244156785e-06, 1.1204775485273674e-06, 2.790918041040276e-05, 4.84320438084906e-05, 0.000106291207438, 7.01945468622942e-05, 7.684472355661581e-05, 3.26891416841198e-05, 3.083539187374376e-05, 2.89968827862511e-05, 3.74659769720667e-05, 7.51165799076034e-05, 4.9754379359096896e-05, 5.020700241743e-05, 1.6527716285640108e-05, 4.67106626220815e-06, 7.27273660166401e-06, 1.8304595401006607e-05, 6.482582226561359e-06, 2.1888762501979215e-05, 6.79336106389404e-05, 6.39101114642593e-05, 0.0001056179699709, 7.25355644724665e-05, 0.0001296102308913, 7.01724068111877e-05, 6.077442308972321e-05, 3.17019329118447e-05, 4.94680131079957e-05, 3.14950640072424e-05, 3.62797103605345e-05, 4.5406053701595e-05, 3.66622870648494e-05, 2.8679542314911407e-05, 7.43418668883668e-06, 3.84347725610011e-05, 4.01711748970128e-05, 6.225897557228429e-05, 5.76929464274885e-05, 5.81551378448159e-05, 9.26809633940415e-05, 6.18742916844315e-05, 0.0001118116813868, 7.374146214795391e-05, 9.52096699834397e-05, 4.00177097640014e-05, 5.7512075208345005e-05, 2.89078351769274e-05, 2.49220441554606e-05, 3.74528715694122e-05, 1.7876819431951617e-05, 2.781363157459606e-06, 5.00107542969273e-06, 7.606817830648487e-06, 2.575443755567529e-05, 7.79055781002888e-05, 7.06372130124481e-05, 8.30709246424225e-05, 0.0001382072461993, 9.782170571420928e-05, 0.0001358389852699, 6.92325079657172e-05, 9.39867148887521e-05, 6.644476680991369e-05, 9.78033693223552e-05, 6.85165779988513e-05, 7.06234036634149e-05, 0.0001118755330731, 5.15603882962847e-05, 4.15491102853858e-05, 1.133829723596181e-05, 1.315924526537949e-05, 1.59671155987128e-06, 2.99187667505294e-06, 4.069476896933739e-05, 4.4194820236083296e-05, 8.80663826381458e-05, 7.18958113315416e-05, 0.0001231452021587, 7.28502836123535e-05, 8.51307608574589e-05, 4.317935506198531e-05, 2.62994164137922e-05, 3.417296406132888e-05, 3.24611636362833e-05, 7.21455925915349e-05, 6.075731339744381e-05, 7.970546593540381e-05, 4.7723643986572304e-05, 2.94479422952904e-05, 6.393739259817469e-06, 4.50492778903357e-06, 1.822135651964388e-05, 3.72611332077643e-05, 7.63429285708568e-05, 5.79452611417675e-05, 8.73603205741884e-05, 4.51573655447398e-05, 3.1303999644372e-05, 5.9732229655456805e-05, 6.82104488651981e-05, 0.000135308411565, 7.497538051095721e-05, 8.64922177812439e-05, 5.4410632149393794e-05, 3.84514152142844e-05, 4.35620385141933e-05, 3.77626562110816e-05, 7.94579219040163e-05, 5.123002695776531e-05, 4.89703636014259e-05, 2.2927413752903296e-05, 2.91047412871294e-05, 4.87162328583171e-05, 4.725991736443151e-05, 8.363108447573221e-05, 5.7947975558557296e-05, 6.972306844204551e-05, 1.988071800200656e-05, 8.23194984010244e-06, 1.6052347824415152e-05, 1.935230159799809e-05, 5.84195402101422e-05, 5.30441289065083e-05, 7.025905548887809e-05, 3.6161735636529e-05, 3.04422060865953e-05, 3.88038046673116e-05, 2.44627639809778e-05, 3.847080842928511e-05, 3.90846586089017e-05, 6.290141381511339e-05, 3.54430164012933e-05, 3.3040723768153804e-05, 4.324082345261859e-05, 1.184006900171067e-05, 2.3127334702758587e-06, 5.59167830245931e-06, 1.470119112184352e-05, 1.336132271651174e-05, 2.79392029842261e-05, 8.14320475746195e-05, 6.285546981309851e-05, 7.803331137936549e-05, 3.81495790679855e-05, 4.51726134917036e-05, 2.36432699434981e-05, 2.29102450082402e-05, 5.819336559301821e-05, 5.62773547819629e-05, 6.5437707407772e-05, 3.99432111877712e-05, 3.91226659907502e-05, 6.85342337023851e-05, 6.152184084343849e-05, 9.19323872707438e-05, 6.81482288364696e-05, 0.0001035207417468, 5.85664296314886e-05, 4.85815229434042e-05, 4.78277207665953e-05, 1.6485532961216818e-05, 1.3489984188222148e-05, 6.3306697164817805e-06, 3.6648820384340165e-05, 4.17161058427504e-05, 5.38183387240264e-05, 6.888069231391131e-05, 4.26935361268397e-05, 3.5124887981597634e-05, 1.445315960892197e-05, 3.5854096598992294e-07, 7.261300647412708e-06, 2.075739941802853e-05, 5.37607131064746e-05, 4.26053344386204e-05, 9.020874111255448e-05, 5.048933354276549e-05, 3.6055883102978e-05, 3.6242724982193e-05, 2.91295375392664e-05, 5.911223926237021e-05, 3.46276298564951e-05, 3.65952052994831e-05, 6.20573013629939e-05, 4.6258945921342e-05, 7.33162429001938e-05, 6.064980028138731e-05, 0.0001222996323996, 7.668654818893369e-05, 6.49286911973168e-05, 7.31927077473444e-05, 4.58157683415879e-05, 7.19186892513639e-05, 4.36700411814424e-05, 3.78344780319473e-05, 5.13158862075942e-05, 6.55558183653328e-06, 8.40043021662484e-06, 4.82835339753159e-06, 1.334871866436481e-05, 1.974074501849512e-05, 3.05598783159781e-05, 6.71340035723912e-05, 4.95726163188735e-05, 7.010588677301371e-05, 4.56877091080481e-05, 2.7519606230071e-05, 1.859161899596423e-05, 6.64510450208524e-06, 6.854675889635779e-06, 9.91584261866228e-07, 7.34630123005979e-06, 1.349503952453617e-05, 8.998875911247809e-06, 4.102332821176352e-05, 4.9319488193863705e-05, 6.50422413478201e-05, 8.8733010516782e-05, 4.734321334838941e-05, 4.573025343471129e-05, 9.735643300607847e-06, 3.6534040615764977e-06, 1.258736984210349e-06, 4.58793490503342e-06, 3.097570992472589e-05, 3.939657310559441e-05, 9.392815745512888e-05, 6.55870660864653e-05, 5.95878595013357e-05, 9.81285297290606e-05, 5.32426358972225e-05, 6.39880297572358e-05, 2.88519064472755e-05, 2.8883088984689095e-05, 5.1742090806210906e-05, 2.184647372186428e-05, 2.826422627392736e-05, 3.90917458619778e-05, 3.41998197530926e-05, 4.603986421022e-05, 3.80514508201216e-05, 6.557917220415739e-05, 3.08849246494247e-05, 6.02624857878006e-06, 1.0558957005547037e-05, 8.90233498655655e-06, 1.072332911947957e-05, 3.10067823139637e-05, 5.53097478191217e-05, 8.27013494369046e-05, 3.7394025322736e-05, 3.345600451377355e-05, 2.1554602290512894e-05, 1.508584669583058e-05, 3.3809503587571574e-05, 3.8784279908321104e-05, 4.47553485650813e-05, 1.7611708480827002e-05, 1.749567142071329e-05, 2.02662399289819e-05, 5.6793770715132695e-06, 1.051082547782847e-06, 1.0996406558353668e-05, 1.147850571830974e-05, 5.1899836328023e-06, 2.1352518568713373e-05, 6.91884388327196e-05, 6.9223835372404e-05, 7.39768825361018e-05, 9.33772280865984e-05, 4.76890079047848e-05, 5.4800769402740105e-05, 2.74753687800766e-05, 3.3268434407777607e-05, 6.80677553351349e-05, 7.133750934798649e-05, 0.0001120415455877, 6.184987220363329e-05, 4.95346358104208e-05, 5.79639401646385e-05, 2.5815706217996804e-05, 2.156493197869028e-05, 5.24302751637633e-06, 4.99349904269799e-06, 5.99947403552987e-06, 1.72283177694455e-06, 1.1503621038138474e-05, 1.95737179446391e-05, 3.1548945361268804e-05, 6.699432642909349e-05, 6.21761095554606e-05, 0.0001063799030228, 6.65470170265556e-05, 5.10728209540914e-05, 6.952408073728121e-05, 2.88156456678493e-05, 1.468844172721003e-05, 1.711159926470638e-05, 1.844669186499017e-05, 5.38666352949568e-05, 4.10504047668026e-05, 4.13484488440398e-05, 8.262707162669949e-05, 5.1778741694004206e-05, 6.77459624812653e-05, 3.27172055830116e-05, 1.8236074987418333e-05, 3.181985768149304e-05, 2.10324322864806e-05, 5.84263645265956e-05, 5.520704190270109e-05, 5.50041093385821e-05, 9.97235069766942e-05, 6.94911902609184e-05, 8.777828196203079e-05, 5.12398844974656e-05, 4.627737199145741e-05, 6.33171300164753e-05, 1.511457404874409e-05, 4.13019203204214e-08, 8.967414423615332e-06, 2.144119537535599e-05, 4.41337836873228e-05, 3.92562100559858e-05, 5.03847506417002e-05, 8.53645904661172e-05, 4.3116220650783e-05, 6.59588621452017e-05, 6.0786626389316606e-05, 8.127684909843571e-05, 0.000123391887825, 7.61399628589075e-05, 6.976627289692581e-05, 8.66512910389574e-05, 3.74550155100575e-05, 3.95079302581057e-05, 2.51176851169923e-05, 2.50979550003865e-05, 4.17479885496996e-05, 3.82480750840123e-05, 6.96296255471013e-05, 5.263001604285031e-05, 5.92085182189213e-05, 9.258744237755932e-05, 4.36027903584222e-05, 3.5507280169754296e-05, 2.571526910105321e-05, 5.4158119745761005e-06, 1.559891546235876e-05, 5.255328146886991e-06, 8.291671247817891e-06, 1.3173104180180952e-05, 3.5485472119364502e-06, 1.338576216935329e-05, 2.18359450525492e-05, 3.55747507473909e-05, 6.93299173545468e-05, 4.122543069682791e-05, 3.34207242640463e-05, 2.9346441499686348e-05, 7.13444449496791e-06, 2.0528584087324463e-05, 4.53426390227898e-05, 6.169965364712261e-05, 9.3949302144584e-05, 5.52444740332702e-05, 4.18956402198513e-05, 3.72009240249358e-05, 9.72356240595731e-06, 2.465300772674303e-05, 2.56483763800526e-05, 3.781188506818569e-05, 7.81272435874592e-05, 6.34641879315934e-05, 6.65736108426637e-05, 8.73939521650114e-05, 5.3662667135059e-05, 6.75908371284941e-05, 2.99186316579071e-05, 3.47265063947074e-05, 6.595869720316911e-05, 5.66945395340214e-05, 6.34511844554609e-05, 9.51175477786509e-05, 7.61015652281424e-05, 0.0001120895025588, 6.82708223637129e-05, 6.18174918793951e-05, 8.937064079255321e-05, 6.09956737852717e-05, 4.97654240655168e-05, 6.35797341671499e-05, 4.47986056758891e-05, 5.37318147796612e-05, 1.501662651589345e-05, 1.946038351187816e-06, 2.395803101538205e-06, 9.824088928585773e-06, 1.7370287269517602e-06, 1.707812363032436e-05, 3.3821793667895504e-05, 6.56400191129646e-05, 5.52678243346299e-05, 6.18002077289016e-05, 9.6302462136255e-05, 7.573733636992791e-05, 6.2419086484441e-05, 9.24880354357164e-05, 6.41263189872059e-05, 4.60374300605753e-05, 4.40765785905013e-05, 1.502367562895786e-05, 6.58132382265347e-06, 1.6085472547315022e-05, 1.795897396146483e-05, 5.49810955318791e-05, 4.34492496061382e-05, 3.740976975170929e-05, 7.024992226120509e-05, 4.67630506508808e-05, 6.0503973823145305e-05, 4.98385707021413e-05, 5.4743044064731696e-05, 8.67862083873201e-05, 5.47314799548713e-05, 6.21056692614699e-05, 8.610319156937909e-05, 4.8269012696954695e-05, 2.77950016982196e-05, 1.22587237785648e-05, 3.0467120280079973e-06, 5.58241027277777e-06, 3.09126985252071e-06, 1.5019688300661638e-05, 4.036972089556638e-05, 5.8825829899092e-05, 7.389681573174989e-05, 0.0001297916316665, 0.0001012080998149, 9.85320347950941e-05, 0.0001060672332551, 4.15912166711641e-05, 4.46473362994786e-05, 2.083417691086702e-05, 1.347277925024017e-05, 2.5083981297239e-05, 1.50330739336797e-05, 1.707139682236778e-05, 3.6965934992243096e-05, 1.6670376047192752e-05, 1.291721947313727e-05, 2.794296288559144e-05, 2.68007687496405e-05, 4.16900104284704e-05, 4.904565644310156e-06, 1.09793270858049e-06, 1.3109237587407562e-05, 7.81391429148234e-06, 1.1020705185367971e-05, 4.770102192629731e-05, 5.05348110218693e-05, 5.04519644054031e-05, 5.83510334841988e-05, 2.61875937301223e-05, 3.58564120444349e-05, 1.458591711230666e-05, 6.25307325204065e-06, 7.091725728453587e-06, 1.307578644758126e-05, 2.6913582857025e-05, 6.0320412810642296e-05, 4.31420042823873e-05, 5.77226012161352e-05, 9.14459209797646e-05, 4.36485470624136e-05, 2.97885244742836e-05, 4.10550096019944e-05, 2.79538549199972e-05, 3.646431896151401e-05, 1.507212425747665e-05, 3.93900374131765e-05, 8.44092740954298e-05, 5.22716794372394e-05, 4.691855017950821e-05, 5.379018548382831e-05, 2.77360873326808e-05, 3.2242020103996004e-05, 1.424660836622838e-05, 1.131498900925053e-05, 2.80544812730576e-05, 4.8242383890814e-05, 3.68504879545534e-05, 3.38081020106888e-05, 5.24707814329499e-05, 4.27070474158715e-05, 6.19821820867356e-05, 5.496631188575551e-05, 7.12643869395649e-05, 9.613638123120812e-05, 4.79666178067749e-05, 3.46112181244884e-05, 2.711182269762322e-05, 6.55165833205431e-06, 5.80072835602241e-06, 2.8149969513381335e-05, 2.0654544790200097e-05, 1.913705661114699e-05, 2.959274327520913e-05, 2.39097463003306e-05, 2.30456338544048e-05, 4.98968851641599e-05, 4.6664209901483495e-05, 6.01099650573446e-05, 8.883237335009141e-05, 4.863556113916591e-05, 6.24519604638999e-05, 2.571738354933605e-05, 6.639501614833031e-06, 2.64701508305691e-06, 9.21628912978649e-06, 1.35733203977642e-05, 2.9042912144247592e-05, 2.48507327039618e-05, 2.37931787447592e-05, 4.73202447063905e-05, 3.79967824905508e-05, 3.4462641940009e-05, 4.01601208380657e-05, 1.640212945485856e-05, 1.82867499658305e-05, 2.201964213406705e-05, 1.050915959830495e-05, 1.6874614077604638e-05, 5.38491140338104e-05, 5.01415277563732e-05, 3.8113913584483095e-05, 3.66392289470954e-05, 2.6111465335936404e-05, 3.11785401440868e-05, 6.74249619992158e-05, 6.92211022478114e-05, 0.0001304371922913, 9.16495711757855e-05, 7.03111763182789e-05, 4.96857664365206e-05, 1.6845368670290848e-05, 7.47231522166774e-06, 1.72053779976359e-06, 6.04583502415192e-06, 3.74341366779279e-06, 1.308268170294951e-05, 3.48341281897956e-05, 4.64084672475708e-05, 0.0001005500407535, 8.30387679451153e-05, 8.23157560764904e-05, 0.0001168131548089, 5.41577326212577e-05, 3.9183417297707695e-05, 7.401398825391e-05, 4.1138023328341495e-05, 2.085134024720681e-05, 2.385307025736721e-05, 2.32436322963708e-05, 3.1813938116274e-05, 3.77913504039332e-05, 3.25873742286819e-05, 4.74188522170324e-05, 5.742115032652109e-05, 2.169696180689595e-05, 1.2517002131564032e-05, 2.296220804212997e-05, 1.957373317718156e-05, 1.890257610282529e-05, 6.0194090931774805e-05, 5.2880170207399006e-05, 4.79491908990579e-05, 5.99317913018937e-05, 4.74648445385256e-05, 5.179334979750879e-05, 6.97729410536361e-05, 4.15330815822092e-05, 4.29740310113319e-05, 4.490724488069111e-05, 9.85136064310212e-06, 1.027939175344815e-05, 4.2679829015874993e-05, 4.381119788259861e-05, 3.8147456416787895e-05, 3.66403650750178e-05, 2.14472255922594e-05, 5.89092418924255e-06, 3.46836695065304e-06, 1.526938900780292e-05, 2.09760884571503e-05, 3.7222141533024e-05, 2.61597147850295e-05, 3.14937935013035e-05, 8.18478641929553e-05, 7.20333716532289e-05, 7.979923160154342e-05, 0.0001258845670432, 6.7859356143679e-05, 6.20147567728584e-05, 7.75172737474799e-05, 4.08532832355304e-05, 3.58097212289749e-05, 6.91113327670376e-05, 2.67337824193189e-05, 1.871210298487078e-05, 4.4794846006236205e-06, 1.548059379200307e-05, 1.763539830077305e-05, 2.3724403420226707e-05, 1.43496932856642e-05, 1.940701061319809e-05, 1.811167359199792e-05, 5.06680078800882e-06, 2.48148056456841e-06, 1.937449372139252e-05, 2.1591268934488696e-05, 3.59081246602694e-05, 7.50460061532556e-05, 5.00815782297516e-05, 4.03580745437722e-05, 3.1814979951227794e-05, 7.695126276783169e-06, 3.146822161691601e-06, 1.205344621108602e-05, 5.65244221853356e-05, 9.19551244588496e-05, 0.0001429968724935, 8.315442714745679e-05, 6.6258653814739e-05, 8.35321104166972e-05, 3.54017259556767e-05, 1.8238368268157066e-05, 6.03204513378555e-05, 4.79180974560533e-05, 3.4115981909800804e-05, 5.19793134691494e-05, 3.9402918996971e-05, 5.79840928040081e-05, 0.0001053528160947, 6.706029434844861e-05, 6.09051261736662e-05, 7.87714511583373e-05, 4.0615598996072297e-05, 2.67130395572374e-05, 3.15886936850621e-05, 2.1302026499523e-05, 1.475123521608716e-05, 1.403112634446645e-05, 4.41045446359119e-06, 1.449077838792552e-05, 2.31687394261676e-05, 3.21673188420768e-05, 2.94592120303281e-05, 3.3658648282034495e-05, 3.326913584272266e-05, 9.948808669660728e-06, 3.28971540703037e-06, 1.612964648050443e-05, 1.00952409344967e-05, 1.627599795304485e-05, 5.20092794564454e-05, 4.12089287089673e-05, 4.402294072376711e-05, 8.553724216615199e-05, 6.492432089108359e-05, 6.54850409488651e-05, 9.009863813498968e-05, 5.922357820619821e-05, 6.16461496641975e-05, 7.7189758518513e-05, 3.07234205126628e-05, 3.74567254909266e-05, 4.156724106450551e-05, 1.3999475266451671e-05, 1.954219829763871e-05, 2.10040234733831e-05, 3.9646497111865696e-05, 2.409288428382938e-05, 2.45038644631719e-06, 2.40984321787209e-05, 2.1221318760785e-05, 2.44995827448823e-05, 5.47950065630431e-05, 4.70244857783913e-05, 6.574369771250321e-05, 0.0001038601757609, 5.43655675500025e-05, 5.201061147233e-05, 3.027652250217857e-05, 3.96905162095573e-07, 5.82169009385486e-07, 1.062849896238857e-05, 4.21457591549312e-05, 7.0236664680863e-05, 8.81658665962628e-05, 0.0001317907606878, 6.0751139661255e-05, 4.2211265497198505e-05, 5.4363534977097e-05, 1.7332927848880982e-05, 2.23365042948426e-05, 6.278571565699e-05, 6.178911049382069e-05, 6.73352536603169e-05, 7.55564359284537e-05, 3.20451223126619e-05, 2.029155360214749e-05, 7.645702390630286e-06, 1.07784197356317e-06, 3.4667120434254366e-06, 1.635484659158015e-05, 3.616776132459501e-05, 3.4923343517686496e-05, 5.22188198862745e-05, 9.87151854715116e-05, 7.24858673134627e-05, 7.34595949633555e-05, 8.1817041588804e-05, 4.86980107191996e-05, 4.85397793665665e-05, 0.0001069313748246, 8.726045454170179e-05, 8.18552648446694e-05, 6.959787520156791e-05, 9.309340379031192e-05, 6.03986031836695e-05, 7.23329080404169e-05, 0.0001297530331327, 0.0001000968911692, 9.37239054028638e-05, 8.84302336120883e-05, 3.1354157981874e-05, 9.47885049934438e-06, 4.38626586234814e-06, 3.83944686234596e-06, 9.171191111523453e-06, 1.622312470383378e-05, 5.18258600236295e-05, 4.51951438018155e-05, 4.71767041724261e-05, 7.93845786437988e-05, 5.492647368183289e-05, 5.64329376715223e-05, 6.90225911691006e-05, 4.3327012673940606e-05, 4.14508398778594e-05, 6.36309475755983e-05, 4.60916344286728e-05, 6.440576081173359e-05, 7.85406656409995e-05, 0.0001192093551717, 7.675645447403491e-05, 6.23911949766207e-05, 6.878567065432881e-05, 1.913057252824503e-05, 5.94534285574175e-06, 2.729970072145203e-05, 1.748048440615598e-05, 2.036500473773508e-05, 2.95992473699598e-05, 5.09337204478056e-05, 3.9914808283528105e-05, 2.3980752864602e-05, 2.827195291089872e-05, 2.8165067881990304e-05, 3.33547890566917e-05, 5.76411950008377e-05, 4.5489933333176e-05, 5.0842357746793695e-05, 5.83689818124687e-05, 7.04922625284864e-05, 2.3287259807103032e-05, 2.95293865313479e-06, 1.7824410886361574e-05, 1.17560762114969e-05, 2.7992215048190297e-05, 5.38082866703949e-05, 4.3645310448783705e-05, 3.43949935997761e-05, 2.3961248357671895e-05, 1.170753007090823e-05, 7.42138796428365e-06, 1.555099481183134e-05, 4.47757775648927e-05, 5.44886001481552e-05, 5.828645115284379e-05, 9.26422154371994e-05, 6.71518888467177e-05, 7.06331225629254e-05, 7.107596203334869e-05, 0.0001080604125383, 6.33087717259786e-05, 5.7084354680076e-05, 5.66076519724422e-05, 1.887820964911393e-05, 1.2982649961056929e-05, 3.616192011694264e-05, 4.06372607729267e-05, 4.04189019902366e-05, 2.49979180351693e-05, 2.943746167789907e-05, 1.670562980606105e-05, 2.41548244966468e-05, 7.18734200155782e-05, 6.98215806556719e-05, 7.707315782497981e-05, 7.452480076397021e-05, 9.82406242807224e-05, 5.731065249901069e-05, 5.74212576431716e-05, 6.98275395033269e-05, 4.56383363419598e-05, 5.49429765981021e-05, 7.21917249853552e-05, 5.35582152224347e-05, 5.3371070450064e-05, 5.0546509706847896e-05, 5.545557007113061e-05, 1.823493937886557e-05, 8.683310032559951e-06, 1.2982424948376e-05, 5.443947845500339e-07, 7.16008855890816e-06, 2.391161360020838e-05, 8.52542981776832e-05, 8.8218873978254e-05, 9.62051504164423e-05, 0.0001464552033094, 8.376211200252949e-05, 7.821578925406511e-05, 6.79656841104113e-05, 0.0001044618950512, 6.79353483045891e-05, 5.63187968699669e-05, 6.957467496127571e-05, 3.84171863972437e-05, 3.6380696964205405e-05, 2.80035167299844e-05, 3.47404155756186e-05, 3.34843321710845e-05, 3.99634991303746e-05, 3.195503966243956e-05, 4.02139575118338e-06, 6.01869676992156e-06, 8.03693169473332e-06, 2.0706442725401e-05, 2.42851973126654e-05, 4.3001721607552e-05, 8.84038315592615e-05, 4.91727116851986e-05, 2.90485763588229e-05, 1.549890062342022e-05, 8.892894510809281e-06, 2.64086099584276e-06, 1.003050525146252e-05, 3.44858970313782e-05, 3.49624631236982e-05, 4.15122514581547e-05, 3.68716950124872e-05, 8.61076989172506e-05, 8.186989015014691e-05, 8.29801870520896e-05, 0.0001354205160154, 9.39419813841521e-05, 9.29878385480951e-05, 8.504871545880229e-05, 7.803940615041231e-05, 2.67746386283504e-05, 2.3962857866709305e-05, 2.249667074706321e-05, 5.45593287215175e-06, 0.0, 4.38910826296963e-06, 1.297235564676365e-05, 2.32981103823203e-05, 2.45020797466384e-05, 6.18482895055325e-05, 5.16168547412153e-05, 5.64075094333746e-05, 5.4496637400477005e-05, 7.8079692591095e-05, 3.81134407763433e-05, 4.58181979555692e-05, 7.050604329228021e-05, 4.6590774830881e-05, 4.8466750051735104e-05, 3.47736504527799e-05, 4.39206345518942e-05, 3.01593491386255e-05, 1.63557434850646e-05, 2.0945421183931e-05, 6.57302488124261e-05, 4.83833117340716e-05, 6.465965640911e-05, 8.17423100949965e-05, 4.98875633246477e-05, 5.472644833264551e-05, 4.26855758593911e-05, 1.9060020411122615e-05, 5.24984674642489e-06, 1.070789979999126e-05, 3.92366836578905e-05, 4.0551510248693095e-05, 6.61158684296378e-05, 8.62074894479779e-05, 0.0001195837418341, 4.82863726463282e-05, 2.650744451506764e-05, 1.89214537333679e-05, 2.9482321654427363e-05, 2.7855847657869403e-05, 3.82985528270188e-05, 6.4196386176273e-05, 4.17852100644244e-05, 3.0140182231265095e-05, 1.607992229791254e-05, 2.96307869124193e-06, 3.24706082753458e-06, 5.84048227724846e-06, 3.712138324535627e-06, 8.18076226915873e-06, 3.2605221360981795e-05, 4.289426210647659e-05, 6.9347191662326e-05, 4.86277491894533e-05, 6.011939706062821e-05, 6.09278987889804e-05, 6.61710614961865e-05, 3.11208723871373e-05, 2.8165326403606297e-05, 2.6743949622209706e-05, 3.68254035823934e-05, 2.6628308655281706e-05, 4.9073042034399605e-05, 0.0001046640526727, 7.46432480938173e-05, 7.85121551093399e-05, 7.953628879511191e-05, 0.0001189380775057, 7.212007073670369e-05, 4.53810046367141e-05, 3.10680740623456e-05, 2.580913754952077e-05, 1.73409354010901e-07, 4.7328151197349e-06, 2.8332506743105843e-05, 4.52586660554197e-05, 7.464293392609279e-05, 6.570213691695621e-05, 8.829588161247829e-05, 6.13217426748584e-05, 5.67262618851917e-05, 5.23265046830668e-05, 5.66302151385833e-05, 2.70113857930417e-05, 2.5608789799115603e-05, 2.1303828086938023e-05, 2.839719166417131e-05, 4.1659690933305e-05, 5.9812941463621705e-05, 0.0001052089240491, 7.58051448618133e-05, 7.698096074639971e-05, 6.898863629666341e-05, 4.2666350121314896e-05, 1.233370429722685e-05, 4.94214629333564e-06, 7.80945870731747e-06, 2.011956077360184e-05, 2.053066195224511e-05, 3.92695668394975e-05, 4.48938404829084e-05, 5.74695448071714e-05, 4.32221586676113e-05, 5.46173297399868e-05, 8.15114520552352e-05, 4.78126380824492e-05, 2.5794391227975096e-05, 1.598979106605414e-05, 1.798116018217227e-05, 2.184584388809118e-05, 3.5569958947487496e-05, 5.2211502793355296e-05, 0.0001035597181063, 6.58370664159946e-05, 4.86677193607961e-05, 3.9995877662244e-05, 5.16609653691134e-05, 3.77979369733868e-05, 3.76271485276907e-05, 5.1554704583449e-05, 0.0001002317631185, 6.55543122196542e-05, 3.77948791015902e-05, 1.989521767935149e-05, 1.758861744924212e-05, 3.985793209706957e-06, 3.2513702646453498e-06, 4.748638161842789e-05, 5.802537717182381e-05, 7.050670517959811e-05, 8.234299368470611e-05, 0.0001061556726112, 6.92399344020469e-05, 6.73306907346629e-05, 6.35101864565531e-05, 7.517049059693631e-05, 1.737681099531418e-05, 8.03425036597961e-06, 8.661029791514779e-06, 1.4477404473670649e-05, 2.90715226407984e-05, 3.18465401493842e-05, 6.2750692639344e-05, 0.0001204153988335, 7.21387428410973e-05, 6.78721951763686e-05, 6.77913472859662e-05, 9.3362007235126e-05, 6.399935613133809e-05, 3.08806962541322e-05, 6.27076479298653e-06, 4.1338923962794e-06, 3.8474179746525603e-07, 5.36814505996137e-06, 2.2706958546093217e-05, 6.15560875614246e-05, 6.07943657890021e-05, 5.63249008554948e-05, 7.14445158322194e-05, 5.15090527885072e-05, 4.37958953744716e-05, 2.52533643780647e-05]\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Check the type of the first element in the MALDI_binned column\n",
    "print(type(df['MALDI_binned'][0]))\n",
    "# Convert the string representation of the list to an actual list\n",
    "maldi_binned_array = ast.literal_eval(df['MALDI_binned'][0])\n",
    "print(maldi_binned_array)\n",
    "print(len(maldi_binned_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "      <th>Erythromycin</th>\n",
       "      <th>Ciprofloxacin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000254  0.000395  0.000453  0.000495  0.000801  0.000879  0.001296   \n",
       "1  0.000339  0.000203  0.000097  0.000844  0.000769  0.000667  0.000974   \n",
       "2  0.000123  0.000162  0.000089  0.000671  0.000563  0.001250  0.001091   \n",
       "3  0.000282  0.000608  0.000158  0.000486  0.000495  0.000468  0.000414   \n",
       "4  0.000370  0.000243  0.000149  0.000620  0.000307  0.000999  0.000981   \n",
       "\n",
       "          7         8         9  ...      5992      5993      5994      5995  \\\n",
       "0  0.000631  0.000040  0.000295  ...  0.000023  0.000062  0.000061  0.000056   \n",
       "1  0.000557  0.000116  0.000038  ...  0.000056  0.000074  0.000096  0.000154   \n",
       "2  0.000240  0.000078  0.000060  ...  0.000029  0.000055  0.000112  0.000084   \n",
       "3  0.000147  0.000160  0.000277  ...  0.000037  0.000015  0.000003  0.000004   \n",
       "4  0.000304  0.000262  0.000104  ...  0.000050  0.000037  0.000025  0.000051   \n",
       "\n",
       "       5996      5997      5998      5999  Erythromycin  Ciprofloxacin  \n",
       "0  0.000071  0.000052  0.000044  0.000025           0.0            0.0  \n",
       "1  0.000075  0.000067  0.000042  0.000022           0.0            0.0  \n",
       "2  0.000072  0.000060  0.000046  0.000003           1.0            0.0  \n",
       "3  0.000021  0.000036  0.000045  0.000096           0.0            1.0  \n",
       "4  0.000056  0.000078  0.000099  0.000140           0.0            0.0  \n",
       "\n",
       "[5 rows x 6002 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'MALDI_binned' column from string representation of list to actual list\n",
    "df['MALDI_binned'] = df['MALDI_binned'].apply(ast.literal_eval)\n",
    "\n",
    "# Create a new DataFrame with 6000 columns from the 'MALDI_binned' column\n",
    "maldi_binned_df = pd.DataFrame(df['MALDI_binned'].tolist(), index=df.index)\n",
    "\n",
    "# Concatenate the new DataFrame with the original DataFrame (excluding the original 'MALDI_binned' column)\n",
    "df_expanded = pd.concat([maldi_binned_df, df.drop(columns=['MALDI_binned'])], axis=1)\n",
    "\n",
    "# Display the new DataFrame\n",
    "df_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases en el conjunto de entrenamiento:\n",
      "Erythromycin\n",
      "0.0    1387\n",
      "1.0     344\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución de clases en el conjunto de prueba:\n",
      "Ciprofloxacin\n",
      "0.0    1614\n",
      "1.0     117\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar la cantidad de instancias de cada clase en el conjunto de entrenamiento\n",
    "class_counts_erytro = df_expanded['Erythromycin'].value_counts()\n",
    "print(\"Distribución de clases Erythromycin:\")\n",
    "print(class_counts_erytro)\n",
    "\n",
    "# Contar la cantidad de instancias de cada clase en el conjunto de prueba\n",
    "class_counts_cipro = df_expanded['Ciprofloxacin'].value_counts()\n",
    "print(\"\\nDistribución de clases Ciprofloxacin:\")\n",
    "print(class_counts_cipro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1384, 6000)\n",
      "X_test shape: (347, 6000)\n",
      "y_train shape: (1384, 1)\n",
      "y_test shape: (347, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df_expanded.drop(columns=['Erythromycin', 'Ciprofloxacin'])\n",
    "y = df_expanded[['Erythromycin']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1656: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Using LassoCV for feature selection\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m lasso \u001b[38;5;241m=\u001b[39m \u001b[43mLassoCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Getting the selected features based on the coefficients\u001b[39;00m\n\u001b[0;32m      8\u001b[0m selected_features_lasso \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(lasso\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:2128\u001b[0m, in \u001b[0;36mLassoCV.fit\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   2090\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m   2091\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Lasso model with coordinate descent.\u001b[39;00m\n\u001b[0;32m   2092\u001b[0m \n\u001b[0;32m   2093\u001b[0m \u001b[38;5;124;03m    Fit is on grid of alphas and best alpha estimated by cross-validation.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;124;03m        Returns an instance of fitted model.\u001b[39;00m\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1784\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;66;03m# We do a double for loop folded in one, in order to be able to\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# iterate in parallel on l1_ratio and folds\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m jobs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1767\u001b[0m     delayed(_path_residuals)(\n\u001b[0;32m   1768\u001b[0m         X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m folds\n\u001b[0;32m   1783\u001b[0m )\n\u001b[1;32m-> 1784\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(mse_paths, (n_l1_ratio, \u001b[38;5;28mlen\u001b[39m(folds), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;66;03m# The mean is computed over folds.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e-02, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.692e-02, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.840e-02, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.966e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e-02, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.089e-02, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e-02, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.367e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.162e-02, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.271e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.735e-02, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.202e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.561e-02, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.383e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.864e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.093e-02, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.033e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.827e-02, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.102e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.561e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.650e-02, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.046e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.693e-02, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.934e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.092e-02, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.678e-02, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.355e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.368e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.553e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.336e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.944e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.981e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.788e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.493e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.737e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.257e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.192e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.304e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.878e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.860e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.680e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.407e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.345e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.914e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.672e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.573e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.236e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.330e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.045e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.742e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.508e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.621e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.785e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.419e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.317e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.915e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.330e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.348e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.118e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.805e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.720e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.435e-01, tolerance: 1.769e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.655e-01, tolerance: 1.816e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.167e-01, tolerance: 1.751e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.822e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\guigr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.320e-01, tolerance: 1.739e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Using LassoCV for feature selection\n",
    "lasso = LassoCV(cv=5, random_state=0, max_iter=1000, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "# Getting the selected features based on the coefficients\n",
    "selected_features_lasso = np.where(lasso.coef_ != 0)[0]\n",
    "\n",
    "print(f\"Number of features selected by LASSO: {len(selected_features_lasso)}\")\n",
    "print(f\"Selected features: {selected_features_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Training the logistic regression model using only selected features\n",
    "model = LogisticRegression(max_iter=1000, random_state=0)\n",
    "model.fit(X_train[:, selected_features_lasso], y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_test[:, selected_features_lasso])\n",
    "\n",
    "# Calculating Balanced Accuracy Score\n",
    "score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy Score: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
